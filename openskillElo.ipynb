{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The default Firebase app already exists. This means you called initialize_app() more than once without providing an app name as the second argument. In most cases you only need to call initialize_app() once. But if you do want to initialize multiple apps, pass a second argument to initialize_app() to give each app a unique name.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfirebase_admin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m firestore\n\u001b[1;32m      7\u001b[0m cred \u001b[38;5;241m=\u001b[39m credentials\u001b[38;5;241m.\u001b[39mCertificate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthecrowsnestapp-creds.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mfirebase_admin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_app\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m db \u001b[38;5;241m=\u001b[39m firestore\u001b[38;5;241m.\u001b[39mclient()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.13.1/lib/python3.13/site-packages/firebase_admin/__init__.py:74\u001b[0m, in \u001b[0;36minitialize_app\u001b[0;34m(credential, options, name)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m app\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m _DEFAULT_APP_NAME:\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m((\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe default Firebase app already exists. This means you called \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitialize_app() more than once without providing an app name as \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe second argument. In most cases you only need to call \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitialize_app() once. But if you do want to initialize multiple \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapps, pass a second argument to initialize_app() to give each app \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma unique name.\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m((\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirebase app named \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m already exists. This means you called \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitialize_app() more than once with the same app name as the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msecond argument. Make sure you provide a unique name every time \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myou call initialize_app().\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(name))\n",
      "\u001b[0;31mValueError\u001b[0m: The default Firebase app already exists. This means you called initialize_app() more than once without providing an app name as the second argument. In most cases you only need to call initialize_app() once. But if you do want to initialize multiple apps, pass a second argument to initialize_app() to give each app a unique name."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "\n",
    "cred = credentials.Certificate(\"thecrowsnestapp-creds.json\")\n",
    "firebase_admin.initialize_app(cred)\n",
    "\n",
    "db = firestore.client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openskill.models import PlackettLuce, BradleyTerryFull\n",
    "model = PlackettLuce(beta=25.0/120.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext scalene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetElo = 1000\n",
    "baseElo = 500\n",
    "targetSeason = 'f24'\n",
    "# baseSigma = baseElo // 3\n",
    "# offset = baseElo * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sailor:\n",
    "    def __init__(self, name,key, year, links, teams, seasons=[], skipperRank=0, crewRank=0,skipperRating=baseElo, crewRating=baseElo, races=[], gender=\"\"):\n",
    "        self.name = name\n",
    "        self.key = key\n",
    "        self.gender = gender\n",
    "        self.year = year\n",
    "        self.links = links\n",
    "        self.teams = teams\n",
    "        self.skipperRank = skipperRank\n",
    "        self.crewRank = crewRank\n",
    "        self.womenSkipperRank = skipperRank\n",
    "        self.womenCrewRank = crewRank\n",
    "        self.seasons = seasons\n",
    "        self.races = []\n",
    "        self.rivals = {}\n",
    "        # self.sr = model.rating(skipperRating, skipperRating / 3, name)\n",
    "        # self.cr = model.rating(crewRating, crewRating / 3, name)\n",
    "        \n",
    "        # fleet racing\n",
    "        self.wsr = model.rating(name=name)\n",
    "        self.wcr = model.rating(name=name)\n",
    "        self.sr = model.rating(name=name)\n",
    "        self.cr = model.rating(name=name)\n",
    "        # Team racing \n",
    "        self.wtsr = model.rating(name=name)\n",
    "        self.wtcr = model.rating(name=name)\n",
    "        self.tsr = model.rating(name=name)\n",
    "        self.tcr = model.rating(name=name)\n",
    "        self.avgSkipperRatio = 0\n",
    "        self.avgCrewRatio = 0\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"{self.name}: {self.teams}, {str(self.sr.ordinal())} {str(self.cr.ordinal())} {self.seasons} {len(self.races)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_race_id(row):\n",
    "    if row['Scoring'] == 'Combined':\n",
    "        return row['raceID'][:-1]  # Remove the last character (A/B) for combined scoring\n",
    "    return row['raceID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Div</th>\n",
       "      <th>Sailor</th>\n",
       "      <th>Link</th>\n",
       "      <th>GradYear</th>\n",
       "      <th>Position</th>\n",
       "      <th>Partner</th>\n",
       "      <th>PartnerLink</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Regatta</th>\n",
       "      <th>Scoring</th>\n",
       "      <th>raceID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Team</th>\n",
       "      <th>Teamlink</th>\n",
       "      <th>raceNum</th>\n",
       "      <th>raceDiv</th>\n",
       "      <th>adjusted_raceID</th>\n",
       "      <th>key</th>\n",
       "      <th>partnerKey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Campbell D'Eliscu</td>\n",
       "      <td>campbell-deliscu</td>\n",
       "      <td>19</td>\n",
       "      <td>Skipper</td>\n",
       "      <td>Meaghan MacRae</td>\n",
       "      <td>meaghan-macrae</td>\n",
       "      <td>Southern Cal</td>\n",
       "      <td>f16/rose-bowl-backup</td>\n",
       "      <td>2 Divisions</td>\n",
       "      <td>f16/rose-bowl-backup/1A</td>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>Georgetown</td>\n",
       "      <td>/schools/georgetown/f16/</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>f16/rose-bowl-backup/1A</td>\n",
       "      <td>campbell-deliscu</td>\n",
       "      <td>meaghan-macrae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Campbell D'Eliscu</td>\n",
       "      <td>campbell-deliscu</td>\n",
       "      <td>19</td>\n",
       "      <td>Skipper</td>\n",
       "      <td>Meaghan MacRae</td>\n",
       "      <td>meaghan-macrae</td>\n",
       "      <td>Southern Cal</td>\n",
       "      <td>f16/rose-bowl-backup</td>\n",
       "      <td>2 Divisions</td>\n",
       "      <td>f16/rose-bowl-backup/2A</td>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>Georgetown</td>\n",
       "      <td>/schools/georgetown/f16/</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>f16/rose-bowl-backup/2A</td>\n",
       "      <td>campbell-deliscu</td>\n",
       "      <td>meaghan-macrae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Campbell D'Eliscu</td>\n",
       "      <td>campbell-deliscu</td>\n",
       "      <td>19</td>\n",
       "      <td>Skipper</td>\n",
       "      <td>Meaghan MacRae</td>\n",
       "      <td>meaghan-macrae</td>\n",
       "      <td>Southern Cal</td>\n",
       "      <td>f16/rose-bowl-backup</td>\n",
       "      <td>2 Divisions</td>\n",
       "      <td>f16/rose-bowl-backup/3A</td>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>Georgetown</td>\n",
       "      <td>/schools/georgetown/f16/</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>f16/rose-bowl-backup/3A</td>\n",
       "      <td>campbell-deliscu</td>\n",
       "      <td>meaghan-macrae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>B</td>\n",
       "      <td>Sean Segerblom</td>\n",
       "      <td>sean-segerblom</td>\n",
       "      <td>20</td>\n",
       "      <td>Skipper</td>\n",
       "      <td>Claire Mohun</td>\n",
       "      <td>claire-mohun</td>\n",
       "      <td>Southern Cal</td>\n",
       "      <td>f16/rose-bowl-backup</td>\n",
       "      <td>2 Divisions</td>\n",
       "      <td>f16/rose-bowl-backup/1B</td>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>Georgetown</td>\n",
       "      <td>/schools/georgetown/f16/</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>f16/rose-bowl-backup/1B</td>\n",
       "      <td>sean-segerblom</td>\n",
       "      <td>claire-mohun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>B</td>\n",
       "      <td>Sean Segerblom</td>\n",
       "      <td>sean-segerblom</td>\n",
       "      <td>20</td>\n",
       "      <td>Skipper</td>\n",
       "      <td>Claire Mohun</td>\n",
       "      <td>claire-mohun</td>\n",
       "      <td>Southern Cal</td>\n",
       "      <td>f16/rose-bowl-backup</td>\n",
       "      <td>2 Divisions</td>\n",
       "      <td>f16/rose-bowl-backup/2B</td>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>Georgetown</td>\n",
       "      <td>/schools/georgetown/f16/</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>f16/rose-bowl-backup/2B</td>\n",
       "      <td>sean-segerblom</td>\n",
       "      <td>claire-mohun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788903</th>\n",
       "      <td>14.0</td>\n",
       "      <td>B</td>\n",
       "      <td>Chloe Lighterink</td>\n",
       "      <td>chloe-lighterink</td>\n",
       "      <td>24</td>\n",
       "      <td>Crew</td>\n",
       "      <td>Claire Desbaillets</td>\n",
       "      <td>None</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>s24/peter-wenner-rainbow-invite</td>\n",
       "      <td>2 Divisions</td>\n",
       "      <td>s24/peter-wenner-rainbow-invite/7B</td>\n",
       "      <td>2024-01-20</td>\n",
       "      <td>UC Davis</td>\n",
       "      <td>/schools/uc-davis/s24/</td>\n",
       "      <td>7</td>\n",
       "      <td>B</td>\n",
       "      <td>s24/peter-wenner-rainbow-invite/7B</td>\n",
       "      <td>chloe-lighterink</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788904</th>\n",
       "      <td>16.0</td>\n",
       "      <td>B</td>\n",
       "      <td>Chloe Lighterink</td>\n",
       "      <td>chloe-lighterink</td>\n",
       "      <td>24</td>\n",
       "      <td>Crew</td>\n",
       "      <td>Claire Desbaillets</td>\n",
       "      <td>None</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>s24/peter-wenner-rainbow-invite</td>\n",
       "      <td>2 Divisions</td>\n",
       "      <td>s24/peter-wenner-rainbow-invite/8B</td>\n",
       "      <td>2024-01-20</td>\n",
       "      <td>UC Davis</td>\n",
       "      <td>/schools/uc-davis/s24/</td>\n",
       "      <td>8</td>\n",
       "      <td>B</td>\n",
       "      <td>s24/peter-wenner-rainbow-invite/8B</td>\n",
       "      <td>chloe-lighterink</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788905</th>\n",
       "      <td>16.0</td>\n",
       "      <td>B</td>\n",
       "      <td>Chloe Lighterink</td>\n",
       "      <td>chloe-lighterink</td>\n",
       "      <td>24</td>\n",
       "      <td>Crew</td>\n",
       "      <td>Claire Desbaillets</td>\n",
       "      <td>None</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>s24/peter-wenner-rainbow-invite</td>\n",
       "      <td>2 Divisions</td>\n",
       "      <td>s24/peter-wenner-rainbow-invite/9B</td>\n",
       "      <td>2024-01-20</td>\n",
       "      <td>UC Davis</td>\n",
       "      <td>/schools/uc-davis/s24/</td>\n",
       "      <td>9</td>\n",
       "      <td>B</td>\n",
       "      <td>s24/peter-wenner-rainbow-invite/9B</td>\n",
       "      <td>chloe-lighterink</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788906</th>\n",
       "      <td>16.0</td>\n",
       "      <td>B</td>\n",
       "      <td>Chloe Lighterink</td>\n",
       "      <td>chloe-lighterink</td>\n",
       "      <td>24</td>\n",
       "      <td>Crew</td>\n",
       "      <td>Claire Desbaillets</td>\n",
       "      <td>None</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>s24/peter-wenner-rainbow-invite</td>\n",
       "      <td>2 Divisions</td>\n",
       "      <td>s24/peter-wenner-rainbow-invite/10B</td>\n",
       "      <td>2024-01-20</td>\n",
       "      <td>UC Davis</td>\n",
       "      <td>/schools/uc-davis/s24/</td>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>s24/peter-wenner-rainbow-invite/10B</td>\n",
       "      <td>chloe-lighterink</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788907</th>\n",
       "      <td>16.0</td>\n",
       "      <td>B</td>\n",
       "      <td>Chloe Lighterink</td>\n",
       "      <td>chloe-lighterink</td>\n",
       "      <td>24</td>\n",
       "      <td>Crew</td>\n",
       "      <td>Claire Desbaillets</td>\n",
       "      <td>None</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>s24/peter-wenner-rainbow-invite</td>\n",
       "      <td>2 Divisions</td>\n",
       "      <td>s24/peter-wenner-rainbow-invite/11B</td>\n",
       "      <td>2024-01-20</td>\n",
       "      <td>UC Davis</td>\n",
       "      <td>/schools/uc-davis/s24/</td>\n",
       "      <td>11</td>\n",
       "      <td>B</td>\n",
       "      <td>s24/peter-wenner-rainbow-invite/11B</td>\n",
       "      <td>chloe-lighterink</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>788908 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Score Div             Sailor              Link GradYear Position  \\\n",
       "0         1.0   A  Campbell D'Eliscu  campbell-deliscu       19  Skipper   \n",
       "1         2.0   A  Campbell D'Eliscu  campbell-deliscu       19  Skipper   \n",
       "2         1.0   A  Campbell D'Eliscu  campbell-deliscu       19  Skipper   \n",
       "3         3.0   B     Sean Segerblom    sean-segerblom       20  Skipper   \n",
       "4        16.0   B     Sean Segerblom    sean-segerblom       20  Skipper   \n",
       "...       ...  ..                ...               ...      ...      ...   \n",
       "788903   14.0   B   Chloe Lighterink  chloe-lighterink       24     Crew   \n",
       "788904   16.0   B   Chloe Lighterink  chloe-lighterink       24     Crew   \n",
       "788905   16.0   B   Chloe Lighterink  chloe-lighterink       24     Crew   \n",
       "788906   16.0   B   Chloe Lighterink  chloe-lighterink       24     Crew   \n",
       "788907   16.0   B   Chloe Lighterink  chloe-lighterink       24     Crew   \n",
       "\n",
       "                   Partner     PartnerLink         Venue  \\\n",
       "0           Meaghan MacRae  meaghan-macrae  Southern Cal   \n",
       "1           Meaghan MacRae  meaghan-macrae  Southern Cal   \n",
       "2           Meaghan MacRae  meaghan-macrae  Southern Cal   \n",
       "3             Claire Mohun    claire-mohun  Southern Cal   \n",
       "4             Claire Mohun    claire-mohun  Southern Cal   \n",
       "...                    ...             ...           ...   \n",
       "788903  Claire Desbaillets            None        Hawaii   \n",
       "788904  Claire Desbaillets            None        Hawaii   \n",
       "788905  Claire Desbaillets            None        Hawaii   \n",
       "788906  Claire Desbaillets            None        Hawaii   \n",
       "788907  Claire Desbaillets            None        Hawaii   \n",
       "\n",
       "                                Regatta      Scoring  \\\n",
       "0                  f16/rose-bowl-backup  2 Divisions   \n",
       "1                  f16/rose-bowl-backup  2 Divisions   \n",
       "2                  f16/rose-bowl-backup  2 Divisions   \n",
       "3                  f16/rose-bowl-backup  2 Divisions   \n",
       "4                  f16/rose-bowl-backup  2 Divisions   \n",
       "...                                 ...          ...   \n",
       "788903  s24/peter-wenner-rainbow-invite  2 Divisions   \n",
       "788904  s24/peter-wenner-rainbow-invite  2 Divisions   \n",
       "788905  s24/peter-wenner-rainbow-invite  2 Divisions   \n",
       "788906  s24/peter-wenner-rainbow-invite  2 Divisions   \n",
       "788907  s24/peter-wenner-rainbow-invite  2 Divisions   \n",
       "\n",
       "                                     raceID       Date        Team  \\\n",
       "0                   f16/rose-bowl-backup/1A 2017-01-07  Georgetown   \n",
       "1                   f16/rose-bowl-backup/2A 2017-01-07  Georgetown   \n",
       "2                   f16/rose-bowl-backup/3A 2017-01-07  Georgetown   \n",
       "3                   f16/rose-bowl-backup/1B 2017-01-07  Georgetown   \n",
       "4                   f16/rose-bowl-backup/2B 2017-01-07  Georgetown   \n",
       "...                                     ...        ...         ...   \n",
       "788903   s24/peter-wenner-rainbow-invite/7B 2024-01-20    UC Davis   \n",
       "788904   s24/peter-wenner-rainbow-invite/8B 2024-01-20    UC Davis   \n",
       "788905   s24/peter-wenner-rainbow-invite/9B 2024-01-20    UC Davis   \n",
       "788906  s24/peter-wenner-rainbow-invite/10B 2024-01-20    UC Davis   \n",
       "788907  s24/peter-wenner-rainbow-invite/11B 2024-01-20    UC Davis   \n",
       "\n",
       "                        Teamlink  raceNum raceDiv  \\\n",
       "0       /schools/georgetown/f16/        1       A   \n",
       "1       /schools/georgetown/f16/        2       A   \n",
       "2       /schools/georgetown/f16/        3       A   \n",
       "3       /schools/georgetown/f16/        1       B   \n",
       "4       /schools/georgetown/f16/        2       B   \n",
       "...                          ...      ...     ...   \n",
       "788903    /schools/uc-davis/s24/        7       B   \n",
       "788904    /schools/uc-davis/s24/        8       B   \n",
       "788905    /schools/uc-davis/s24/        9       B   \n",
       "788906    /schools/uc-davis/s24/       10       B   \n",
       "788907    /schools/uc-davis/s24/       11       B   \n",
       "\n",
       "                            adjusted_raceID               key      partnerKey  \n",
       "0                   f16/rose-bowl-backup/1A  campbell-deliscu  meaghan-macrae  \n",
       "1                   f16/rose-bowl-backup/2A  campbell-deliscu  meaghan-macrae  \n",
       "2                   f16/rose-bowl-backup/3A  campbell-deliscu  meaghan-macrae  \n",
       "3                   f16/rose-bowl-backup/1B    sean-segerblom    claire-mohun  \n",
       "4                   f16/rose-bowl-backup/2B    sean-segerblom    claire-mohun  \n",
       "...                                     ...               ...             ...  \n",
       "788903   s24/peter-wenner-rainbow-invite/7B  chloe-lighterink            None  \n",
       "788904   s24/peter-wenner-rainbow-invite/8B  chloe-lighterink            None  \n",
       "788905   s24/peter-wenner-rainbow-invite/9B  chloe-lighterink            None  \n",
       "788906  s24/peter-wenner-rainbow-invite/10B  chloe-lighterink            None  \n",
       "788907  s24/peter-wenner-rainbow-invite/11B  chloe-lighterink            None  \n",
       "\n",
       "[788908 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_races = pd.read_json(\"races_new_test2.json\")\n",
    "# converters={\"Teams\": lambda x: [y.strip().split(\"'\")[1] for y in x.strip(\"[]\").split(\", \")]}\n",
    "df_races['raceNum'] = df_races['raceID'].apply(lambda id: int(id.split(\"/\")[2][:-1]))  # Numeric part\n",
    "df_races['raceDiv'] = df_races['raceID'].apply(lambda id: id.split(\"/\")[2][-1])  # Division part (e.g., 'A', 'B')\n",
    "df_races['adjusted_raceID'] = df_races.apply(adjust_race_id, axis=1) # to make combined division combined\n",
    "df_races['Link'] = df_races['Link'].fillna('Unknown') # fill empty links\n",
    "# df_races['key'] = np.where(df_races['Link'] == 'Unknown', df_races['Sailor'], df_races['Link'])\n",
    "df_races['key'] = df_races.apply(\n",
    "    lambda row: row['Sailor'] + \"-\" + row['Team'] if row['Link'] == 'Unknown' else row['Link'],\n",
    "    axis=1\n",
    ")\n",
    "df_races['partnerKey'] = df_races.apply(\n",
    "    lambda row: row['Partner'] + \"-\" + row['Team'] if row['PartnerLink'] == 'Unknown' else row['PartnerLink'],\n",
    "    axis=1\n",
    ")\n",
    "# df_races = df_races[df_races['Regatta'] == 'f24/seisa-women-fall'] # example combined regatta\n",
    "\n",
    "# to exclude f24\n",
    "# df_races = df_races.loc[df_races['raceID'].apply(lambda id: id.split(\"/\")[0] != 'f24')]\n",
    "# df_races = df_races.loc[df_races['raceID'].apply(lambda id: id.split(\"/\")[1] != 'east-open-national-semi-final')]\n",
    "# df_races = df_races.loc[df_races['raceID'].apply(lambda id: id.split(\"/\")[1] != 'open-dinghy-national')]\n",
    "\n",
    "df_races_full = df_races.sort_values(['Date', 'raceNum', 'raceDiv']).reset_index(drop=True)\n",
    "\n",
    "df_races_skipper = df_races_full.loc[df_races_full['Position'].str.contains('Skipper')].sort_values(['Date', 'raceNum']).reset_index(drop=True)\n",
    "df_races_crew = df_races_full.loc[df_races_full['Position'].str.contains('Crew')].sort_values(['Date', 'raceNum']).reset_index(drop=True) \n",
    "\n",
    "df_sailor_info = pd.read_json(\"sailor_data2.json\")\n",
    "# df_sailor_info\n",
    "# df_races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "teamRegions = {'Hawaii': 'PCCSC', 'Brown': 'NEISA', 'Southern Cal': 'PCCSC', 'Salve Regina': 'NEISA', 'UC Santa Barbara': 'PCCSC', 'Cal Poly': 'PCCSC', 'Washington': 'NWICSA', 'Channel Islands': 'PCCSC', 'UC San Diego': 'PCCSC', 'British Columbia': 'NWICSA', 'UC Los Angeles': 'PCCSC', 'Westmont College': 'PCCSC', 'Arizona State': 'PCCSC', 'Texas A&M Galveston': 'SEISA', 'Texas A&M': 'SEISA', 'Tulane': 'SEISA', 'Rice': 'SEISA', 'Texas': 'SEISA', 'Oklahoma State': 'SEISA', 'Texas A&M C. Christ': 'SEISA', 'Central Oklahoma': 'SEISA', 'Notre Dame': 'MCSA', 'Jacksonville': 'SAISA', 'Florida': 'SAISA', 'Tennessee': 'SAISA', 'Rollins': 'SAISA', 'North Carolina State': 'SAISA', 'Georgia Tech': 'SAISA', 'Auburn': 'SAISA', 'Charleston': 'SAISA', 'South Florida': 'SAISA', 'Old Dominion': 'MAISA', 'Eckerd': 'SAISA', 'Florida State': 'SAISA', 'U. Miami': 'SAISA', 'UW Milwaukee': 'MCSA', 'Stony Brook': 'MAISA', 'Duke': 'SAISA', 'Clemson': 'SAISA', 'U South Carolina': 'SAISA', 'UNC Wilmington': 'SAISA', 'Georgia': 'SAISA', 'Berkeley': 'PCCSC', 'CSU Long Beach': 'PCCSC', 'Monterey Bay': 'PCCSC', 'UC Irvine': 'PCCSC', 'UC Davis': 'PCCSC', 'Rhode Island': 'NEISA', 'Georgetown': 'MAISA', 'Dartmouth': 'NEISA', 'MIT': 'NEISA', 'George Washington': 'MAISA', 'Navy': 'MAISA', 'Fordham': 'MAISA', 'Northeastern': 'NEISA', 'Christopher Newport': 'MAISA', 'Victoria': 'NWICSA', 'Boston University': 'NEISA', 'Miami University': 'MCSA', 'Hampton': 'MAISA', 'Virginia': 'MAISA', 'Stevens': 'MAISA', 'Columbia': 'MAISA', 'NY Maritime': 'MAISA', 'Kings Point': 'MAISA', \"St. Mary's\": 'MAISA', 'Maryland': 'MAISA', 'Virginia Tech': 'MAISA', 'Drexel': 'MAISA', 'Maryland/Baltimore': 'MAISA', 'Buffalo': 'MAISA', 'UC Santa Cruz': 'PCCSC', 'Santa Clara': 'PCCSC', 'Wisconsin': 'MCSA', 'Michigan': 'MCSA', 'Washington College': 'MAISA', 'Minnesota': 'MCSA', 'Yale': 'NEISA', 'Hobart & William': 'MAISA', 'Vermont': 'NEISA', 'Connecticut College': 'NEISA', 'Harvard': 'NEISA', 'Roger Williams': 'NEISA', 'Syracuse': 'MAISA', 'Tufts': 'NEISA', 'Middlebury': 'NEISA', 'New College': 'SAISA', 'William and Mary': 'MAISA', 'Gannon': 'MAISA', 'Boston College': 'NEISA', 'Stanford': 'PCCSC', 'Bowdoin': 'NEISA', 'Lewis & Clark': 'NWICSA', 'Monmouth': 'MAISA', 'American': 'MAISA', 'Michigan State': 'MCSA', 'Hope': 'MCSA', 'Western Michigan': 'MCSA', 'Toledo': 'MCSA', 'Ohio State': 'MCSA', 'Mass Maritime': 'NEISA', 'Coast Guard': 'NEISA', 'Bates': 'NEISA', 'Fairfield': 'NEISA', 'Sacred Heart': 'NEISA', 'Wentworth Institute': 'NEISA', 'Providence': 'NEISA', 'Iowa State': 'MCSA', 'Iowa': 'MCSA', 'Indiana': 'MCSA', 'Davidson': 'SAISA', 'Oregon State': 'NWICSA', 'Western Washington': 'NWICSA', 'U. Rochester': 'MAISA', 'Army': 'MAISA', 'New Hampshire': 'NEISA', 'U. Connecticut': 'NEISA', 'UMass Dartmouth': 'NEISA', 'Wesleyan': 'NEISA', 'U. Mass/ Amherst': 'NEISA', 'U New England': 'NEISA', 'Denison': 'MCSA', 'Northern Michigan': 'MCSA', 'Ohio': 'MCSA', 'Pennsylvania': 'MAISA', 'Villanova': 'MAISA', 'Maine Maritime': 'NEISA', 'Michigan Tech': 'MCSA', 'Illinois': 'MCSA', 'Chicago': 'MCSA', 'Northwestern': 'MCSA', 'Grand Valley State': 'MCSA', 'Washington U': 'MCSA', 'Marquette': 'MCSA', 'Lake Forest': 'MCSA', 'Cornell': 'MAISA', 'Oregon': 'NWICSA', 'Portland State': 'NWICSA', 'Princeton': 'MAISA', \"Queen's\": 'MAISA', 'Penn State': 'MAISA', 'Ocean County': 'MAISA', 'Delaware': 'MAISA', 'Rutgers': 'MAISA', 'Worcester Polytech': 'NEISA', 'Emmanuel College': 'NEISA', \"St. John's\": 'MAISA', 'U Pittsburgh': 'MAISA', 'Webb Institute': 'MAISA', 'McGill': 'NEISA', 'Citadel': 'SAISA', 'Colgate': 'MAISA', 'Catholic U America': 'MAISA', 'Loyola College': 'MAISA', 'Ottawa': 'MAISA', 'Royal Military': 'MAISA', 'Dalhousie': 'NEISA', 'U Toronto': 'MAISA', 'New Orleans': 'SEISA', 'Kansas': 'SEISA', 'Bentley': 'NEISA', 'Brandeis': 'NEISA', 'Cal Maritime': 'PCCSC', 'San Diego State': 'PCCSC', 'Loyola': 'SEISA', 'North Texas': 'SEISA', 'Vanderbilt': 'SAISA', 'Purdue': 'MCSA', 'North Carolina': 'SAISA', 'Hillsdale': 'MCSA', 'Amherst': 'NEISA', 'Williams': 'NEISA', 'Hamilton': 'MAISA', 'Rochester': 'MAISA', 'Wellesley': 'NEISA', 'Hosei Univerisity': 'GUEST', 'Colorado': 'SEISA', 'John Carroll': 'MCSA', 'U.  Mass/ Boston': 'NEISA', 'Mercyhurst': 'MAISA', 'Penn State Behrend': 'MAISA', 'Indiana U Pennsylvan': 'MAISA', 'U Nebraska': 'MCSA', 'U Maine': 'NEISA', 'Texas Christian': 'SEISA', 'Embry-Riddle': 'SAISA', 'Palm Beach Atlantic': 'SAISA', 'U of Central Florida': 'SAISA', 'Baldwin-Wallace': 'MCSA', \"Saint Mary's College\": 'MCSA', 'Olin': 'NEISA', 'Baylor': 'SEISA', 'Texas Tech': 'SEISA', 'Wake Forest': 'SAISA', 'Georgia Southern': 'SAISA', 'East Carolina': 'SAISA', 'Florida Tech': 'SAISA', 'Saint Thomas': 'MCSA', 'Cincinnati': 'MCSA', 'Florida Gulf Coast': 'SAISA', 'Saginaw Valley': 'MCSA', 'Coastal Georgia': 'SAISA', 'Cleveland State': 'MCSA', 'Sewanee': 'SAISA', 'Case Western': 'MCSA', 'Oklahoma': 'SEISA', 'Gonzaga': 'PCCSC'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merges = [{'first': 'carter-anderson', 'second': 'carter-anderson-2027'}, {'first': 'elliott-bates', 'second':'elliott-bates-2021'}, {'first': 'ian-hopkins-guerra','second': 'ian-hopkins-guerra-2026'}, {'first': 'connor-nelson', 'second':'connor-nelson-2024'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add a sailor to the dictionary\n",
    "def add_sailor(group,names_group, links_group, seasons_group,teams_group, years_group, people):\n",
    "    \"\"\"Summary\n",
    "\n",
    "    Args:\n",
    "        group (pandas group): The grouped list of sailor keys and teams\n",
    "        names_group (pandas group): The list of names grouped by sailor key\n",
    "        links_group (pandas group): The list of links grouped by sailor key\n",
    "        seasons_group (pandas group): The list of seasons grouped by sailor key\n",
    "        teams_group (pandas group): The list of teams grouped by sailor key\n",
    "        years_group (pandas group): The list of years grouped by sailor key\n",
    "        people (dict): The people dictionary to be added to\n",
    "    \"\"\"\n",
    "\n",
    "    for key, teams in group.items():\n",
    "        if key not in people.keys():\n",
    "            # If no teams are associated, set \"Unknown\"\n",
    "            teams = teams if len(teams) > 0 else [\"Unknown\"]\n",
    "\n",
    "            # Retrieve the precomputed values\n",
    "            name = names_group.get(key,[])[0]\n",
    "            link = links_group.get(key,[])\n",
    "            seasons = seasons_group.get(key,[])\n",
    "            teams = teams_group.get(key,[])\n",
    "            year = years_group.get(key, [])[0]\n",
    "            gender = \"\"\n",
    "            \n",
    "            if key in list(df_sailor_info['link']):\n",
    "                data = df_sailor_info.loc[df_sailor_info['link'] == key]\n",
    "                gender = data['gender'].iat[0]\n",
    "                year = data['year'].iat[0]\n",
    "            \n",
    "            # Add the sailor to the people dictionary\n",
    "            people[key] = Sailor(name, key, year, list([link]), teams, {'skipper': seasons.get('Skipper', []), 'crew': seasons.get('Crew', [])}, gender=gender)\n",
    "            \n",
    "def setupPeople():\n",
    "    \"\"\"Generates a dictionary with all of the sailors based on the df_races_full dataframe\n",
    "\n",
    "    Returns:\n",
    "        dict: The filled out dictionary of people\n",
    "    \"\"\"\n",
    "    \n",
    "    people = {}\n",
    "    \n",
    "    try:\n",
    "        df_s = pd.read_json(\"sailorsasf.json\")\n",
    "    except:\n",
    "        df_s = pd.DataFrame(columns=['Sailor'])\n",
    "\n",
    "    # create sailors from file (NOT WORKING)\n",
    "    for sailor in list(df_s['Sailor'].unique()):\n",
    "        # print(sailor)\n",
    "        positions = df_s.loc[df_s['Sailor'] == sailor, 'Pos']\n",
    "        for pos in positions:\n",
    "            teams = df_s.loc[(df_s['Sailor'] == sailor)& (df_s['Pos'] == pos), 'Teams'].iat[0]\n",
    "            seasons = df_s.loc[(df_s['Sailor'] == sailor) & (df_s['Pos'] == pos), 'Seasons'].iat[0]\n",
    "            year = df_s.loc[(df_s['Sailor'] == sailor) & (df_s['Pos'] == pos), 'GradYear'].iat[0]\n",
    "            link = df_s.loc[(df_s['Sailor'] == sailor) & (df_s['Pos'] == pos), 'Link'].iat[0]\n",
    "            rating = df_s.loc[(df_s['Sailor'] == sailor) & (df_s['Pos'] == pos), 'Elo'].iat[0]\n",
    "            rank = df_s.loc[(df_s['Sailor'] == sailor) & (df_s['Pos'] == pos), 'Rank'].iat[0]\n",
    "            races = df_s.loc[(df_s['Sailor'] == sailor) & (df_s['Pos'] == pos), 'Races'].iat[0]\n",
    "            people[link] = Sailor(sailor, year, link, teams, pos, seasons, rank, rating, races)\n",
    "    \n",
    "    # Do merges if necessary (merging two techscore links)\n",
    "    # We must merge here before the calculation is done, because each new rating will need the accurate history\n",
    "    for merge in merges:\n",
    "        if merge['second'] in people.keys():\n",
    "            people[merge['first']].links.append(people[merge['second']])\n",
    "            del people[merge['second']]\n",
    "        df_races_full['key'] = df_races_full['key'].replace(merge['second'], merge['first'])\n",
    "        df_races_skipper['key'] = df_races_skipper['key'].replace(merge['second'], merge['first'])\n",
    "        df_races_crew['key'] = df_races_crew['key'].replace(merge['second'], merge['first'])\n",
    "\n",
    "    # Pre-group the data for skippers and crews\n",
    "    grouped = df_races_full.groupby(['key'])['Team'].unique()\n",
    "    \n",
    "    # Precompute seasons for skippers and crew\n",
    "    names = (\n",
    "        df_races_full.assign(Season=df_races_full['raceID'].str.split('/').str[0])\n",
    "        .groupby('key')['Sailor']\n",
    "        .unique()\n",
    "    )\n",
    "    links = (\n",
    "        df_races_full.assign(Season=df_races_full['raceID'].str.split('/').str[0])\n",
    "        .groupby('key')['Link']\n",
    "        .unique()\n",
    "    )\n",
    "    seasons = (\n",
    "        df_races_full.assign(Season=df_races_full['raceID'].str.split('/').str[0])\n",
    "        .groupby(['key', 'Position'])['Season']\n",
    "        .unique()\n",
    "    )\n",
    "    teams = (\n",
    "        df_races_full.assign(Season=df_races_full['raceID'].str.split('/').str[0])\n",
    "        .groupby('key')['Team']\n",
    "        .unique()\n",
    "    )\n",
    "\n",
    "    years = (\n",
    "        df_races_full.assign(Season=df_races_full['raceID'].str.split('/').str[0])\n",
    "        .groupby('key')['GradYear']\n",
    "        .unique()\n",
    "    )\n",
    "    \n",
    "    # Add all sailors to the people dictionary\n",
    "    add_sailor(grouped, names, links, seasons, teams, years, people)\n",
    "    \n",
    "    return people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently analyzing race 0/65162 Regatta:s16/peter-wenner-rainbow-invite, Date:2016-01-16 00:00:00\n",
      "Currently analyzing race 1000/65162 Regatta:s16/vietor, Date:2016-03-19 00:00:00\n",
      "Currently analyzing race 2000/65162 Regatta:s16/oberg, Date:2016-04-16 00:00:00\n",
      "Currently analyzing race 3000/65162 Regatta:s16/nwicsa-co-ed-fleet-race, Date:2016-04-30 00:00:00\n",
      "Currently analyzing race 4000/65162 Regatta:f16/fj-invitational, Date:2016-09-11 00:00:00\n",
      "Currently analyzing race 5000/65162 Regatta:f16/st-mary-fall-interconference, Date:2016-09-24 00:00:00\n",
      "Currently analyzing race 6000/65162 Regatta:f16/david-lee-arnoff, Date:2016-10-08 00:00:00\n",
      "Currently analyzing race 7000/65162 Regatta:f16/women-atlantic-coast-backup, Date:2016-11-12 00:00:00\n",
      "Currently analyzing race 8000/65162 Regatta:s17/hawkeye-invitational, Date:2017-03-25 00:00:00\n",
      "Currently analyzing race 9000/65162 Regatta:s17/alymers, Date:2017-04-08 00:00:00\n",
      "Currently analyzing race 10000/65162 Regatta:s17/army-spring-open, Date:2017-04-29 00:00:00\n",
      "Currently analyzing race 11000/65162 Regatta:f17/jack-boehringer-52, Date:2017-09-09 00:00:00\n",
      "Currently analyzing race 12000/65162 Regatta:f17/saisa-women-fall, Date:2017-09-30 00:00:00\n",
      "Currently analyzing race 13000/65162 Regatta:f17/jefferson-cup, Date:2017-10-14 00:00:00\n",
      "Currently analyzing race 14000/65162 Regatta:f17/cedarfest, Date:2017-10-28 00:00:00\n",
      "Currently analyzing race 15000/65162 Regatta:s18/odu-spring-women, Date:2018-03-03 00:00:00\n",
      "Currently analyzing race 16000/65162 Regatta:s18/saisa-co-ed-champs, Date:2018-04-07 00:00:00\n",
      "Currently analyzing race 17000/65162 Regatta:s18/delaware-spring-open-2018, Date:2018-04-21 00:00:00\n",
      "Currently analyzing race 18000/65162 Regatta:f18/jack-boehringer-52, Date:2018-09-08 00:00:00\n",
      "Currently analyzing race 19000/65162 Regatta:f18/top-women, Date:2018-09-22 00:00:00\n",
      "Currently analyzing race 20000/65162 Regatta:f18/harvard-coed-showcase, Date:2018-10-06 00:00:00\n",
      "Currently analyzing race 21000/65162 Regatta:f18/cascadia-cup-varsity, Date:2018-10-20 00:00:00\n",
      "Currently analyzing race 22000/65162 Regatta:f18/fall-pacific-coast, Date:2018-11-10 00:00:00\n",
      "Currently analyzing race 23000/65162 Regatta:s19/st-mary-women-interconference, Date:2019-03-16 00:00:00\n",
      "Currently analyzing race 24000/65162 Regatta:s19/navy-spring, Date:2019-04-13 00:00:00\n",
      "Currently analyzing race 25000/65162 Regatta:s19/pccsc-coed-dinghy-conference-championships, Date:2019-04-27 00:00:00\n",
      "Currently analyzing race 26000/65162 Regatta:f19/harvard-invitational, Date:2019-09-08 00:00:00\n",
      "Currently analyzing race 27000/65162 Regatta:f19/women-showcase, Date:2019-09-28 00:00:00\n",
      "Currently analyzing race 28000/65162 Regatta:f19/nevins, Date:2019-10-05 00:00:00\n",
      "Currently analyzing race 29000/65162 Regatta:f19/ucsd-open, Date:2019-10-19 00:00:00\n",
      "Currently analyzing race 30000/65162 Regatta:s20/harris-kempner, Date:2020-02-08 00:00:00\n",
      "Currently analyzing race 31000/65162 Regatta:s21/thompson, Date:2021-04-10 00:00:00\n",
      "Currently analyzing race 32000/65162 Regatta:f21/nicholas-barnett, Date:2021-09-18 00:00:00\n",
      "Currently analyzing race 33000/65162 Regatta:f21/tom-curtis, Date:2021-10-02 00:00:00\n",
      "Currently analyzing race 34000/65162 Regatta:f21/coed-acc-round-1a, Date:2021-10-09 00:00:00\n",
      "Currently analyzing race 35000/65162 Regatta:f21/atlantic-coast-finals, Date:2021-10-23 00:00:00\n",
      "Currently analyzing race 36000/65162 Regatta:s22/jeff-simon-coed, Date:2022-01-29 00:00:00\n",
      "Currently analyzing race 37000/65162 Regatta:s22/north-designate-st-francis, Date:2022-04-02 00:00:00\n",
      "Currently analyzing race 38000/65162 Regatta:s22/george-morris, Date:2022-04-23 00:00:00\n",
      "Currently analyzing race 39000/65162 Regatta:s22/sailing-women-west-semis, Date:2022-05-23 00:00:00\n",
      "Currently analyzing race 40000/65162 Regatta:f22/oyster-bowl, Date:2022-09-24 00:00:00\n",
      "Currently analyzing race 41000/65162 Regatta:f22/hewitt, Date:2022-10-08 00:00:00\n",
      "Currently analyzing race 42000/65162 Regatta:f22/rebecca-blank, Date:2022-10-15 00:00:00\n",
      "Currently analyzing race 43000/65162 Regatta:f22/maisa-fall-women, Date:2022-10-29 00:00:00\n",
      "Currently analyzing race 44000/65162 Regatta:s23/pccsc-south-designate-semis, Date:2023-03-25 00:00:00\n",
      "Currently analyzing race 45000/65162 Regatta:s23/azalea-bowl, Date:2023-04-15 00:00:00\n",
      "Currently analyzing race 46000/65162 Regatta:s23/drexel-open, Date:2023-05-06 00:00:00\n",
      "Currently analyzing race 47000/65162 Regatta:f23/cazenovia-fall-open, Date:2023-09-23 00:00:00\n",
      "Currently analyzing race 48000/65162 Regatta:f23/open-accs-round-1b, Date:2023-10-07 00:00:00\n",
      "Currently analyzing race 49000/65162 Regatta:f23/kathryn-hammond, Date:2023-10-14 00:00:00\n",
      "Currently analyzing race 50000/65162 Regatta:f23/maisa-women-fall-dinghy, Date:2023-10-28 00:00:00\n",
      "Currently analyzing race 51000/65162 Regatta:s24/mustang-open, Date:2024-02-24 00:00:00\n",
      "Currently analyzing race 52000/65162 Regatta:s24/duckling, Date:2024-04-06 00:00:00\n",
      "Currently analyzing race 53000/65162 Regatta:s24/women-new-england-fleet-race, Date:2024-04-20 00:00:00\n",
      "Currently analyzing race 54000/65162 Regatta:f24/saisa-top-invite, Date:2024-09-07 00:00:00\n",
      "Currently analyzing race 55000/65162 Regatta:f24/callagy-ross, Date:2024-09-21 00:00:00\n",
      "Currently analyzing race 56000/65162 Regatta:f24/jefferson-cup, Date:2024-10-05 00:00:00\n",
      "Currently analyzing race 57000/65162 Regatta:f24/women-atlantic-coast-finals, Date:2024-10-12 00:00:00\n",
      "Currently analyzing race 58000/65162 Regatta:f24/neisa-fall-tournament, Date:2024-10-26 00:00:00\n",
      "0.16726308309222881 17.934917009288867\n"
     ]
    }
   ],
   "source": [
    "# %%scalene # for profiling the code\n",
    "\n",
    "# Set up people dictionary\n",
    "people = setupPeople()\n",
    "# Pre calculate the number of races to rate\n",
    "leng = len(df_races['raceID'].unique()) * 2\n",
    "\n",
    "# List of residuals (errors)\n",
    "residuals = []\n",
    "\n",
    "# Current race count for print statement\n",
    "i = 0\n",
    "\n",
    "# Creates pandas group object\n",
    "grouped = df_races_full.groupby(['Date', 'Regatta', 'adjusted_raceID'], sort=False)\n",
    "\n",
    "# Iterate through each race\n",
    "for (date, regatta, race), row in grouped:\n",
    "    # Calculate for each position\n",
    "    for type in ['Skipper', 'Crew']:\n",
    "        \n",
    "        # Print status every 1000 to help with performance and output length\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Currently analyzing race {i}/{leng} Regatta:{regatta}, Date:{date}\")\n",
    "        i += 1\n",
    "        \n",
    "        # Filter by current position \n",
    "        scores = row[row['Position'] == type] \n",
    "        # Grab lists for each datapoint\n",
    "        keys = scores['key'] # the sailor keys\n",
    "        names = scores['Sailor'] # the sailor names\n",
    "        scoreVals = list(scores['Score']) # the score values\n",
    "        \n",
    "        # check for invalid race conditions\n",
    "        if len(keys) < 2: # less than two sailors\n",
    "            continue\n",
    "        if np.isnan(scoreVals[0]): # B division did not complete the set\n",
    "            continue\n",
    "        \n",
    "        # Grab people objects \n",
    "        racers = [people[key] if key != 'Unknown'\n",
    "                and key is not None \n",
    "                else people[name] for key,name in zip(keys,names)]\n",
    "        \n",
    "        # Check for womens regatta\n",
    "        partnerKeys = row[row['Position'] != type]['key']\n",
    "        partnerNames = row[row['Position'] != type]['Sailor']\n",
    "        partners = [people[key] if key != 'Unknown'\n",
    "                and key is not None \n",
    "                else people[name] for key,name in zip(partnerKeys,partnerNames)]\n",
    "        \n",
    "        genders = [p.gender for p in racers + partners]\n",
    "        womenCount = sum([1 if g == \"F\" else 0 for g in genders])\n",
    "        womens = 'M' not in genders and womenCount >= 4\n",
    "        \n",
    "        # Seperate out the openskill rating objects for use in the model\n",
    "        if not womens:\n",
    "            ratings = [[r.sr] if type == 'Skipper' else [r.cr] for r in racers]\n",
    "        else:\n",
    "            ratings = [[r.wsr] if type == 'Skipper' else [r.wcr] for r in racers]\n",
    "\n",
    "        # grab starting rating values for change calculation later\n",
    "        startingRating = [r[0].ordinal(target=targetElo, alpha=200 / model.sigma) for r in ratings]\n",
    "        \n",
    "        # Calculate regatta average\n",
    "        regattaAvg = sum(startingRating) / len(racers)\n",
    "        \n",
    "        # Rate using the model\n",
    "        ratings = model.rate(ratings, scoreVals)\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = model.predict_rank(ratings)\n",
    "        \n",
    "        # calculate error and add to list (residuals)\n",
    "        for pred, score, racer in zip(predictions, scoreVals, racers):\n",
    "            residuals.append(score - pred[0])\n",
    "\n",
    "        # Update racers' ratings\n",
    "        for racer, new_rating in zip(racers, ratings):\n",
    "            if type == 'Skipper':\n",
    "                if womens:\n",
    "                    racer.wsr = new_rating[0]\n",
    "                else: \n",
    "                    racer.sr = new_rating[0]\n",
    "            else:\n",
    "                if womens:\n",
    "                    racer.wcr = new_rating[0]\n",
    "                else:\n",
    "                    racer.cr = new_rating[0]\n",
    "\n",
    "        # Pre-calculate lists for sailor's race values\n",
    "        if womens:\n",
    "            changes = [(racers[i].wsr.ordinal(target=targetElo, alpha=200 / model.sigma) if type == 'Skipper' else racers[i].wcr.ordinal(target=targetElo, alpha=200 / model.sigma)) - startingRating[i] for i in range(len(racers))]\n",
    "        else:\n",
    "            changes = [(racers[i].sr.ordinal(target=targetElo, alpha=200 / model.sigma) if type == 'Skipper' else racers[i].cr.ordinal(target=targetElo, alpha=200 / model.sigma)) - startingRating[i] for i in range(len(racers))]\n",
    "        \n",
    "        # Common values for each sailor\n",
    "        venue = scores['Venue'].iat[0]\n",
    "        scoring = scores['Scoring'].iat[0]\n",
    "        actualID = scores['raceID'].iat[0]\n",
    "        \n",
    "        # Make list of regions and combine PCCSC and NWICSA (those shouldnt count as cross regional for rating purposes)\n",
    "        regions = [teamRegions[p.teams[-1]] if p.teams[-1] in teamRegions.keys() else None for p in racers]\n",
    "        regions = ['PCCSC' if reg == 'NWICSA' else reg for reg in regions]\n",
    "        \n",
    "        # Check if race has any out of region sailors\n",
    "        isCross = 1 if len(set(regions)) > 1 else 0\n",
    "        \n",
    "        # Only calculate number of cross regional sailors if it is the current season\n",
    "        doCr = race.split(\"/\")[0] == targetSeason and isCross == 1\n",
    "        \n",
    "        # Loop through each sailor and the associated values\n",
    "        for sailor, score, pred, change, partner in zip(racers, scoreVals, predictions, changes, partners):\n",
    "            outLinks = 0\n",
    "            \n",
    "            if(isCross == 1):\n",
    "                # Calculate the number of sailors that are not in the sailor's region\n",
    "                outLinks = sum(1 for reg in regions # adds 1 each time that a region in the regatta ... \n",
    "                               if reg is not None # Double check that the region is not none # first double check that the sailor's team is in the list of regions\n",
    "                               and sailor.teams[-1] in teamRegions.keys()\n",
    "                               and ('PCCSC' if reg == 'NWICSA' else reg) != ('PCCSC' if teamRegions[sailor.teams[-1]] == 'NWICSA' else teamRegions[sailor.teams[-1]])) # The sailor's region is not the same as the opponent)\n",
    "                # Note: We don't need to filter out the sailor themselves from this list, because they will have the same region as themseleves so it will not be counted.\n",
    "            \n",
    "            # add race to each sailor's score\n",
    "            sailor.races.append({\n",
    "                'score': int(score), # Need to rewrite to include DNF and such (correctly evaluating score but its hard to tell )\n",
    "                'pos': type,\n",
    "                'predicted': pred[0],\n",
    "                'ratio': 1 - ((int(score) - 1) / (len(racers) - 1)), # Calculate ratio here\n",
    "                'change': change,\n",
    "                'regAvg': regattaAvg,\n",
    "                'cross': isCross,\n",
    "                'outLinks': outLinks,\n",
    "                'skipperRating': sailor.sr.ordinal(target=targetElo, alpha=200 / model.sigma), # add offset to prevent negative ratings\n",
    "                'crewRating': sailor.cr.ordinal(target=targetElo, alpha=200 / model.sigma), # add offset to prevent negative ratings\n",
    "                'womenSkipperRating': sailor.wsr.ordinal(target=targetElo, alpha=200 / model.sigma), # add offset to prevent negative ratings\n",
    "                'womenCrewRating': sailor.wcr.ordinal(target=targetElo, alpha=200 / model.sigma), # add offset to prevent negative ratings\n",
    "                'womens': womens,\n",
    "                'date' :date,\n",
    "                'partner': {'name': partner.name, 'key': partner.key},\n",
    "                'venue': venue,\n",
    "                'raceID': actualID,\n",
    "                'scoring': scoring\n",
    "            })\n",
    "\n",
    "# Calculate statiscs about the accuracy of the model. (Lower is better)\n",
    "me = np.array(residuals).mean()\n",
    "mse = (np.array(residuals) ** 2).mean()\n",
    "print(me, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy = sum([1 for i in residuals if abs(i) == 0]) / len(residuals)\n",
    "# accuracy\n",
    "people['carter-anderson'].gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute season rivals\n",
    "grouped = df_races_full.groupby('adjusted_raceID') # [df_races_full['raceID'].str.startswith('f24')]\n",
    "\n",
    "i = 0\n",
    "leng = len(grouped)\n",
    "for raceID, scores in grouped:\n",
    "    # Report status every 100 races\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Currently analyzing race {i}/{leng} Regatta:{raceID}\")\n",
    "    i += 1\n",
    "    \n",
    "    season = raceID.split(\"/\")[0]\n",
    "    \n",
    "    sailor_scores = scores.set_index('key')[['Position', 'Score', 'Team', 'Sailor']]\n",
    "\n",
    "    for sailor, sailor_data in sailor_scores.iterrows():\n",
    "        pos = sailor_data['Position']\n",
    "        score = sailor_data['Score']\n",
    "        p = people[sailor]\n",
    "        \n",
    "        others = sailor_scores.iterrows()\n",
    "\n",
    "        for other_key, other_sailor_data in others:\n",
    "            if other_key != sailor:\n",
    "                other_pos = other_sailor_data['Position']\n",
    "                if pos == other_pos:\n",
    "                    other_score = other_sailor_data['Score']\n",
    "                    other_team = other_sailor_data['Team']\n",
    "                    other_name = other_sailor_data['Sailor']\n",
    "                    \n",
    "                    if pos not in p.rivals:\n",
    "                        p.rivals[pos] = {}\n",
    "                    \n",
    "                    if other_key not in p.rivals[pos]:\n",
    "                        p.rivals[pos][other_key] = {'name': other_name,'races': {}, 'team': other_team, 'wins': {}}\n",
    "                        \n",
    "                    if season not in p.rivals[pos][other_key]['races'].keys():\n",
    "                        p.rivals[pos][other_key]['races'][season] = 0\n",
    "                    if season not in p.rivals[pos][other_key]['wins'].keys():\n",
    "                        p.rivals[pos][other_key]['wins'][season] = 0\n",
    "                    \n",
    "                    p.rivals[pos][other_key]['races'][season] += 1\n",
    "                    if other_score > score:\n",
    "                        p.rivals[pos][other_key]['wins'][season] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/10/cpsfwdm906d0_fmx9wrl17gh0000gn/T/ipykernel_44780/1184508594.py:29: RuntimeWarning: Mean of empty slice.\n",
      "  avgCrewRatio = float(np.array([r['ratio'] for r in p.races if r['pos'] == 'Crew']).mean())\n",
      "/Users/carter/.pyenv/versions/3.13.1/lib/python3.13/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/var/folders/10/cpsfwdm906d0_fmx9wrl17gh0000gn/T/ipykernel_44780/1184508594.py:28: RuntimeWarning: Mean of empty slice.\n",
      "  avgSkipperRatio = float(np.array([r['ratio'] for r in p.races if r['pos'] == 'Skipper']).mean())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sailor</th>\n",
       "      <th>key</th>\n",
       "      <th>SkipperRank</th>\n",
       "      <th>CrewRank</th>\n",
       "      <th>WomenSkipperRank</th>\n",
       "      <th>WomenCrewRank</th>\n",
       "      <th>Teams</th>\n",
       "      <th>SkipperOrdinal</th>\n",
       "      <th>WomenSkipperOrdinal</th>\n",
       "      <th>CrewOrdinal</th>\n",
       "      <th>...</th>\n",
       "      <th>CrewMU</th>\n",
       "      <th>skipperAvgRatio</th>\n",
       "      <th>crewAvgRatio</th>\n",
       "      <th>SkipperSigma</th>\n",
       "      <th>CrewSigma</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Cross</th>\n",
       "      <th>Races</th>\n",
       "      <th>numRaces</th>\n",
       "      <th>Rivals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.J. Crane</td>\n",
       "      <td>A.J. Crane-Tufts</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Tufts]</td>\n",
       "      <td>1044.264422</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.216095</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>{'skipper': ['s23'], 'crew': []}</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'score': 10, 'pos': 'Skipper', 'predicted': ...</td>\n",
       "      <td>4</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron Babier</td>\n",
       "      <td>Aaron Babier-U Toronto</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[U Toronto]</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>908.866895</td>\n",
       "      <td>...</td>\n",
       "      <td>17.833008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.327381</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>7.210074</td>\n",
       "      <td>{'skipper': [], 'crew': ['f16']}</td>\n",
       "      <td>14</td>\n",
       "      <td>[{'score': 9, 'pos': 'Crew', 'predicted': 9, '...</td>\n",
       "      <td>14</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron Heard</td>\n",
       "      <td>Aaron Heard-Oregon State</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Oregon State]</td>\n",
       "      <td>886.798023</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1083.839610</td>\n",
       "      <td>...</td>\n",
       "      <td>21.211826</td>\n",
       "      <td>0.279270</td>\n",
       "      <td>0.279377</td>\n",
       "      <td>5.889670</td>\n",
       "      <td>5.906170</td>\n",
       "      <td>{'skipper': ['s23', 'f23'], 'crew': ['f22', 's...</td>\n",
       "      <td>6</td>\n",
       "      <td>[{'score': 8, 'pos': 'Crew', 'predicted': 6, '...</td>\n",
       "      <td>41</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron Klein</td>\n",
       "      <td>Aaron Klein-Tufts</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Tufts]</td>\n",
       "      <td>1029.450167</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.911811</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>{'skipper': ['s23'], 'crew': []}</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'score': 9, 'pos': 'Skipper', 'predicted': 1...</td>\n",
       "      <td>6</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Le Roy</td>\n",
       "      <td>Aaron Le Roy-Marquette</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Marquette]</td>\n",
       "      <td>989.631584</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.129880</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>{'skipper': ['s22'], 'crew': []}</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'score': 4, 'pos': 'Skipper', 'predicted': 4...</td>\n",
       "      <td>4</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15014</th>\n",
       "      <td>Zoey Ziskind</td>\n",
       "      <td>zoey-ziskind</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>[Harvard]</td>\n",
       "      <td>1830.750986</td>\n",
       "      <td>2012.012756</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.692464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.851723</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>{'skipper': ['f23', 's24', 'f24'], 'crew': []}</td>\n",
       "      <td>92</td>\n",
       "      <td>[{'score': 2, 'pos': 'Skipper', 'predicted': 6...</td>\n",
       "      <td>165</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15015</th>\n",
       "      <td>Zohar Almani</td>\n",
       "      <td>zohar-almani</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Duke]</td>\n",
       "      <td>997.177026</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.346697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.987239</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>{'skipper': ['f24'], 'crew': []}</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'score': 4, 'pos': 'Skipper', 'predicted': 5...</td>\n",
       "      <td>24</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15016</th>\n",
       "      <td>Zola Johnson</td>\n",
       "      <td>zola-johnson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[U. Miami]</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1275.469130</td>\n",
       "      <td>...</td>\n",
       "      <td>32.236902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.525551</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>6.919674</td>\n",
       "      <td>{'skipper': [], 'crew': ['s16']}</td>\n",
       "      <td>14</td>\n",
       "      <td>[{'score': 9, 'pos': 'Crew', 'predicted': 8, '...</td>\n",
       "      <td>26</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15017</th>\n",
       "      <td>Zuzanna Barska</td>\n",
       "      <td>zuzanna-barska</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Florida]</td>\n",
       "      <td>974.226270</td>\n",
       "      <td>571.047310</td>\n",
       "      <td>692.891386</td>\n",
       "      <td>...</td>\n",
       "      <td>6.843404</td>\n",
       "      <td>0.284585</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>6.507905</td>\n",
       "      <td>6.546532</td>\n",
       "      <td>{'skipper': ['f23'], 'crew': ['s23']}</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'score': 10, 'pos': 'Crew', 'predicted': 8, ...</td>\n",
       "      <td>33</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15018</th>\n",
       "      <td>Zuzanna Ignaszak</td>\n",
       "      <td>zuzanna-ignaszak</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Coastal Georgia]</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>760.255961</td>\n",
       "      <td>...</td>\n",
       "      <td>13.654175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>7.881170</td>\n",
       "      <td>{'skipper': [], 'crew': ['f24']}</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'score': 14, 'pos': 'Crew', 'predicted': 10,...</td>\n",
       "      <td>2</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15019 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Sailor                       key  SkipperRank  CrewRank  \\\n",
       "0            A.J. Crane          A.J. Crane-Tufts            0         0   \n",
       "1          Aaron Babier    Aaron Babier-U Toronto            0         0   \n",
       "2           Aaron Heard  Aaron Heard-Oregon State            0         0   \n",
       "3           Aaron Klein         Aaron Klein-Tufts            0         0   \n",
       "4          Aaron Le Roy    Aaron Le Roy-Marquette            0         0   \n",
       "...                 ...                       ...          ...       ...   \n",
       "15014      Zoey Ziskind              zoey-ziskind          149         0   \n",
       "15015      Zohar Almani              zohar-almani            0         0   \n",
       "15016      Zola Johnson              zola-johnson            0         0   \n",
       "15017    Zuzanna Barska            zuzanna-barska            0         0   \n",
       "15018  Zuzanna Ignaszak          zuzanna-ignaszak            0         0   \n",
       "\n",
       "       WomenSkipperRank  WomenCrewRank              Teams  SkipperOrdinal  \\\n",
       "0                     0              0            [Tufts]     1044.264422   \n",
       "1                     0              0        [U Toronto]     1000.000000   \n",
       "2                     0              0     [Oregon State]      886.798023   \n",
       "3                     0              0            [Tufts]     1029.450167   \n",
       "4                     0              0        [Marquette]      989.631584   \n",
       "...                 ...            ...                ...             ...   \n",
       "15014                18              0          [Harvard]     1830.750986   \n",
       "15015                 0              0             [Duke]      997.177026   \n",
       "15016                 0              0         [U. Miami]     1000.000000   \n",
       "15017                 0              0          [Florida]      974.226270   \n",
       "15018                 0              0  [Coastal Georgia]     1000.000000   \n",
       "\n",
       "       WomenSkipperOrdinal  CrewOrdinal  ...     CrewMU skipperAvgRatio  \\\n",
       "0              1000.000000  1000.000000  ...  25.000000        0.488095   \n",
       "1              1000.000000   908.866895  ...  17.833008             NaN   \n",
       "2              1000.000000  1083.839610  ...  21.211826        0.279270   \n",
       "3              1000.000000  1000.000000  ...  25.000000        0.397436   \n",
       "4              1000.000000  1000.000000  ...  25.000000        0.083333   \n",
       "...                    ...          ...  ...        ...             ...   \n",
       "15014          2012.012756  1000.000000  ...  25.000000        0.692464   \n",
       "15015          1000.000000  1000.000000  ...  25.000000        0.346697   \n",
       "15016          1000.000000  1275.469130  ...  32.236902             NaN   \n",
       "15017           571.047310   692.891386  ...   6.843404        0.284585   \n",
       "15018          1000.000000   760.255961  ...  13.654175             NaN   \n",
       "\n",
       "      crewAvgRatio  SkipperSigma  CrewSigma  \\\n",
       "0              NaN      8.216095   8.333333   \n",
       "1         0.327381      8.333333   7.210074   \n",
       "2         0.279377      5.889670   5.906170   \n",
       "3              NaN      7.911811   8.333333   \n",
       "4              NaN      7.129880   8.333333   \n",
       "...            ...           ...        ...   \n",
       "15014          NaN      5.851723   8.333333   \n",
       "15015          NaN      5.987239   8.333333   \n",
       "15016     0.525551      8.333333   6.919674   \n",
       "15017     0.130000      6.507905   6.546532   \n",
       "15018    -0.083333      8.333333   7.881170   \n",
       "\n",
       "                                                 Seasons  Cross  \\\n",
       "0                       {'skipper': ['s23'], 'crew': []}      0   \n",
       "1                       {'skipper': [], 'crew': ['f16']}     14   \n",
       "2      {'skipper': ['s23', 'f23'], 'crew': ['f22', 's...      6   \n",
       "3                       {'skipper': ['s23'], 'crew': []}      0   \n",
       "4                       {'skipper': ['s22'], 'crew': []}      0   \n",
       "...                                                  ...    ...   \n",
       "15014     {'skipper': ['f23', 's24', 'f24'], 'crew': []}     92   \n",
       "15015                   {'skipper': ['f24'], 'crew': []}      0   \n",
       "15016                   {'skipper': [], 'crew': ['s16']}     14   \n",
       "15017              {'skipper': ['f23'], 'crew': ['s23']}      0   \n",
       "15018                   {'skipper': [], 'crew': ['f24']}      0   \n",
       "\n",
       "                                                   Races  numRaces Rivals  \n",
       "0      [{'score': 10, 'pos': 'Skipper', 'predicted': ...         4     {}  \n",
       "1      [{'score': 9, 'pos': 'Crew', 'predicted': 9, '...        14     {}  \n",
       "2      [{'score': 8, 'pos': 'Crew', 'predicted': 6, '...        41     {}  \n",
       "3      [{'score': 9, 'pos': 'Skipper', 'predicted': 1...         6     {}  \n",
       "4      [{'score': 4, 'pos': 'Skipper', 'predicted': 4...         4     {}  \n",
       "...                                                  ...       ...    ...  \n",
       "15014  [{'score': 2, 'pos': 'Skipper', 'predicted': 6...       165     {}  \n",
       "15015  [{'score': 4, 'pos': 'Skipper', 'predicted': 5...        24     {}  \n",
       "15016  [{'score': 9, 'pos': 'Crew', 'predicted': 8, '...        26     {}  \n",
       "15017  [{'score': 10, 'pos': 'Crew', 'predicted': 8, ...        33     {}  \n",
       "15018  [{'score': 14, 'pos': 'Crew', 'predicted': 10,...         2     {}  \n",
       "\n",
       "[15019 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter sailors who have 'f24' in their seasons list\n",
    "eligible_skippers = [p for p in people.values()\n",
    "                    if targetSeason in p.seasons['skipper'] \n",
    "                    and sum([race['outLinks'] for race in p.races]) > 70]\n",
    "\n",
    "eligible_crews = [p for p in people.values()\n",
    "                    if targetSeason in p.seasons['crew']\n",
    "                    and sum([race['outLinks'] for race in p.races]) > 70]\n",
    "\n",
    "for p in people.values():\n",
    "    p.skipperRank = 0\n",
    "    p.crewRank = 0\n",
    "    p.womenSkipperRank = 0\n",
    "    p.womenCrewRank = 0\n",
    "\n",
    "for i,s in enumerate(sorted([p for p in eligible_skippers], key=lambda p: p.sr.ordinal(), reverse=True)):\n",
    "    s.skipperRank = i + 1\n",
    "for i,s in enumerate(sorted([p for p in eligible_crews], key=lambda p: p.cr.ordinal(), reverse=True)):\n",
    "    s.crewRank = i + 1\n",
    "\n",
    "for i,s in enumerate(sorted([p for p in eligible_skippers], key=lambda p: p.wsr.ordinal(), reverse=True)):\n",
    "    s.womenSkipperRank = i + 1\n",
    "for i,s in enumerate(sorted([p for p in eligible_crews], key=lambda p: p.wcr.ordinal(), reverse=True)):\n",
    "    s.womenCrewRank = i + 1\n",
    "\n",
    "allRows = []\n",
    "for sailor,p in people.items():\n",
    "    avgSkipperRatio = float(np.array([r['ratio'] for r in p.races if r['pos'] == 'Skipper']).mean())\n",
    "    avgCrewRatio = float(np.array([r['ratio'] for r in p.races if r['pos'] == 'Crew']).mean())\n",
    "    p.avgSkipperRatio = avgSkipperRatio\n",
    "    p.avgCrewRatio = avgCrewRatio\n",
    "    allRows.append([p.name, sailor, p.skipperRank,p.crewRank, p.womenSkipperRank, p.womenCrewRank, p.teams, p.sr.ordinal(target=targetElo, alpha=200 / model.sigma), p.wsr.ordinal(target=targetElo, alpha=200 / model.sigma), p.cr.ordinal(target=targetElo, alpha=200 / model.sigma), sum([race['outLinks'] for race in p.races]), p.year, p.links, p.sr.mu, p.cr.mu, avgSkipperRatio,avgCrewRatio, p.sr.sigma, p.cr.sigma, p.seasons, sum([race['cross'] for race in p.races]), p.races,len(p.races), p.rivals])\n",
    "\n",
    "df_sailors = pd.DataFrame(allRows, columns=['Sailor', 'key', 'SkipperRank', 'CrewRank','WomenSkipperRank', 'WomenCrewRank', 'Teams', 'SkipperOrdinal','WomenSkipperOrdinal', 'CrewOrdinal','outLinks','GradYear', 'Links', 'SkipperMU','CrewMU', 'skipperAvgRatio', 'crewAvgRatio', 'SkipperSigma','CrewSigma', 'Seasons', 'Cross', 'Races','numRaces', 'Rivals'])\n",
    "\n",
    "# df_sailors.to_json('sailorsexperiment20.json', index=False)\n",
    "df_sailors.head()\n",
    "df_sailors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'skipper': array(['f23', 's24', 'f24'], dtype=object),\n",
       " 'crew': array(['f23', 's24'], dtype=object)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for r in people['benjamin-stone'].races:\n",
    "#     if r['cross'] == 1:\n",
    "#         print(f\"{r['raceID']} {r['outLinks']}\")\n",
    "        \n",
    "# print(teamRegions['Western Washington'])\n",
    "# print(teamRegions['Oregon State'])\n",
    "# print(teamRegions['Washington'])\n",
    "# print(teamRegions['Oregon'])\n",
    "people['carter-anderson'].seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_ratios = []\n",
    "\n",
    "for rival, stats in people['carter-anderson'].rivals['Skipper'].items():\n",
    "    races = stats['races']\n",
    "    wins = stats['wins']\n",
    "    team = stats['team']\n",
    "    win_ratio = wins / races if races > 0 else 0  # Handle division by zero\n",
    "    win_ratios.append((rival, races, win_ratio, team))\n",
    "\n",
    "# Sort the list by win_ratio in descending order\n",
    "win_ratios_sorted = sorted(win_ratios, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted win ratios\n",
    "for rival, races, win_ratio, team in win_ratios_sorted:\n",
    "    print(f\"{rival}, Team: {team}, Races: {races}, Win Percentage: {win_ratio * 100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updates only changed sailors\n",
    "col = db.collection('sailorsElo')\n",
    "\n",
    "for doc in col.limit(10).stream():\n",
    "    doc_id = doc.id\n",
    "    data = doc.to_dict()\n",
    "    print(doc_id)\n",
    "    changes = {}\n",
    "    person = people[data['Name'] + \"/\" + data['Position']]\n",
    "    if len(person.races) < 1:\n",
    "        print(\"no races found for sailor, skipping...\")\n",
    "        continue\n",
    "\n",
    "    print(data['Name'])\n",
    "    try:\n",
    "        data['Link']\n",
    "    except:\n",
    "        changes['Link'] = list(person.link)[0]\n",
    "        # print(\"No link!\")\n",
    "    try:\n",
    "        data['Year']\n",
    "    except:\n",
    "        changes['Year'] = int(list(person.year)[0][:2])\n",
    "        # print(\"No year!\")\n",
    "\n",
    "    # print(person.races[0])\n",
    "    # check races\n",
    "    changes['races'] = firestore.ArrayUnion(person.races)\n",
    "    # for raceID in [r['raceID'] for r in person.races]:\n",
    "    #     if raceID not in [r['raceID'] for r in data['races']]:\n",
    "    #         changes['races'].append(raceID)\n",
    "    #         print(\"needs update!\", data['races'])\n",
    "    #         print(person.races)\n",
    "    print(changes)\n",
    "    col.document(doc_id).update(changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people['elliott-chalcraft'].races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Firestore client\n",
    "col = db.collection('sailorsElo')\n",
    "\n",
    "# Initialize the batch\n",
    "batch = db.batch()\n",
    "\n",
    "# Number of documents to commit in each batch\n",
    "batch_size = 40\n",
    "\n",
    "# Iterate over the people values\n",
    "# for i, p in enumerate(people.values()):\n",
    "p = people['alice-schmid']\n",
    "# Prepare the document data to be written\n",
    "doc_data = {\n",
    "    \"Name\": p.name,\n",
    "    \"key\": p.key,\n",
    "    'gender': p.gender,\n",
    "    \"Teams\": p.teams.tolist() if isinstance(p.teams, np.ndarray) else p.teams,\n",
    "    \"SkipperRating\": int(p.sr.ordinal(target=targetElo, alpha=200 / model.sigma)),\n",
    "    \"CrewRating\": int(p.cr.ordinal(target=targetElo, alpha=200 / model.sigma)),\n",
    "    \"WomenSkipperRating\": int(p.wsr.ordinal(target=targetElo, alpha=200 / model.sigma)),\n",
    "    \"WomenCrewRating\": int(p.wcr.ordinal(target=targetElo, alpha=200 / model.sigma)),\n",
    "    \"SkipperRank\": int(p.skipperRank),\n",
    "    \"CrewRank\": int(p.crewRank),\n",
    "    \"WomenSkipperRank\": int(p.womenSkipperRank),\n",
    "    \"WomenCrewRank\": int(p.womenCrewRank),\n",
    "    \"Links\": p.links.tolist() if isinstance(p.links, np.ndarray) else p.links if isinstance(p.links, str) else p.links[0].tolist(),\n",
    "    \"Year\": p.year,\n",
    "    \"Seasons\": {'skipper': list(p.seasons['skipper']), 'crew': list(p.seasons['crew'])},\n",
    "    \"Cross\":  sum([race['cross'] for race in p.races]),\n",
    "    \"OutLinks\": sum([race['outLinks'] for race in p.races]),\n",
    "    'races': p.races,\n",
    "    \"Rivals\": p.rivals\n",
    "}\n",
    "\n",
    "# Add the set operation to the batch\n",
    "doc_ref = col.document('Q3i6q6AzS5lftofOFRFU')  # This creates a new document with an auto-generated ID\n",
    "batch.set(doc_ref, doc_data)\n",
    "\n",
    "# Commit the batch every 20 documents\n",
    "# if (i + 1) % batch_size == 0:\n",
    "#     batch.commit()\n",
    "#     batch = db.batch()  # Start a new batch for the next set of documents\n",
    "\n",
    "# Commit any remaining operations if there are less than 20 documents left\n",
    "if (i + 1) % batch_size != 0:\n",
    "    batch.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/207 Hawaii\n",
      "[2096, 1743, 1732] [1912, 1727, 1640] 1808.3333333333333\n",
      "1/207 Brown\n",
      "[2350, 2275, 2264] [2220, 2191, 2183] 2247.1666666666665\n",
      "2/207 Southern Cal\n",
      "[2100, 2036, 1721] [2177, 1867] 1650.1666666666667\n",
      "3/207 Salve Regina\n",
      "[1719, 1707, 1085] [1779, 1501, 1234] 1504.1666666666667\n",
      "4/207 UC Santa Barbara\n",
      "[1900, 1847, 1649] [1846, 1701, 1545] 1748.0\n",
      "5/207 Cal Poly\n",
      "[1619, 1315, 1075] [1676, 1603, 1492] 1463.3333333333333\n",
      "6/207 Washington\n",
      "[1878, 1170, 1025] [2012, 1543, 1358] 1497.6666666666667\n",
      "7/207 Channel Islands\n",
      "[1541] [] 256.8333333333333\n",
      "8/207 UC San Diego\n",
      "[928] [732] 276.6666666666667\n",
      "9/207 British Columbia\n",
      "[] [] 0.0\n",
      "10/207 UC Los Angeles\n",
      "[1184] [868, 684] 456.0\n",
      "11/207 Westmont College\n",
      "12/207 Arizona State\n",
      "[1632, 1077, 997] [1449, 1044] 1033.1666666666667\n",
      "13/207 Texas A&M Galveston\n",
      "[1358] [] 226.33333333333334\n",
      "14/207 Texas A&M\n",
      "[1561, 1513, 1362] [1502, 1364] 1217.0\n",
      "15/207 Tulane\n",
      "[2372, 2266, 2023] [2148, 2045, 1988] 2140.3333333333335\n",
      "16/207 Rice\n",
      "[1542, 1242, 1219] [1574, 1163, 944] 1280.6666666666667\n",
      "17/207 Texas\n",
      "[1783, 1355, 1205] [1599, 1460, 1272] 1445.6666666666667\n",
      "18/207 Oklahoma State\n",
      "19/207 Texas A&M C. Christ\n",
      "[1576] [] 262.6666666666667\n",
      "20/207 Central Oklahoma\n",
      "[] [] 0.0\n",
      "21/207 Notre Dame\n",
      "[] [] 0.0\n",
      "22/207 Jacksonville\n",
      "[2351, 2178, 2052] [2274, 2158, 2013] 2171.0\n",
      "23/207 Florida\n",
      "[] [] 0.0\n",
      "24/207 Tennessee\n",
      "[] [] 0.0\n",
      "25/207 Rollins\n",
      "[1672, 1509, 1143] [1551, 1264, 1099] 1373.0\n",
      "26/207 North Carolina State\n",
      "[1914, 1869, 1825] [1907, 1832, 1705] 1842.0\n",
      "27/207 Georgia Tech\n",
      "[] [] 0.0\n",
      "28/207 Auburn\n",
      "29/207 Charleston\n",
      "[2394, 2363, 2140] [2282, 2228, 2121] 2254.6666666666665\n",
      "30/207 South Florida\n",
      "[2227, 1894, 1882] [1957, 1713, 1662] 1889.1666666666667\n",
      "31/207 Old Dominion\n",
      "[2052, 1910, 1287] [1893, 1809, 1761] 1785.3333333333333\n",
      "32/207 Eckerd\n",
      "[1995, 1626, 1392] [1888, 1532, 1258] 1615.1666666666667\n",
      "33/207 Florida State\n",
      "[1832, 1495, 1370] [1785, 1719, 1494] 1615.8333333333333\n",
      "34/207 U. Miami\n",
      "[2390, 2116, 1882] [2132, 1873, 1331] 1954.0\n",
      "35/207 UW Milwaukee\n",
      "36/207 Stony Brook\n",
      "[1241, 995] [1290, 1077] 767.1666666666666\n",
      "37/207 Duke\n",
      "[] [] 0.0\n",
      "38/207 Clemson\n",
      "[1820, 1805, 1302] [1819, 1743, 1282] 1628.5\n",
      "39/207 U South Carolina\n",
      "[713] [] 118.83333333333333\n",
      "40/207 UNC Wilmington\n",
      "[875, 506, 481] [850] 452.0\n",
      "41/207 Georgia\n",
      "[] [] 0.0\n",
      "42/207 Berkeley\n",
      "[1675, 1622, 1308] [1412, 1391, 1243] 1441.8333333333333\n",
      "43/207 CSU Long Beach\n",
      "44/207 Monterey Bay\n",
      "[] [] 0.0\n",
      "45/207 UC Irvine\n",
      "[] [] 0.0\n",
      "46/207 UC Davis\n",
      "[1344] [] 224.0\n",
      "47/207 Rhode Island\n",
      "[2490, 2098, 1949] [2381, 1954, 1797] 2111.5\n",
      "48/207 Georgetown\n",
      "[2323, 2253, 2240] [2244, 2179, 2173] 2235.3333333333335\n",
      "49/207 Dartmouth\n",
      "[2313, 2266, 2202] [2236, 2124, 1894] 2172.5\n",
      "50/207 MIT\n",
      "[2337, 1963, 1923] [2127, 1816, 1789] 1992.5\n",
      "51/207 George Washington\n",
      "[2098, 1920, 1707] [1836, 1643, 1553] 1792.8333333333333\n",
      "52/207 Navy\n",
      "[2419, 2297, 2271] [2302, 2191, 2080] 2260.0\n",
      "53/207 Fordham\n",
      "[2161, 1970, 1470] [1967, 1837, 1715] 1853.3333333333333\n",
      "54/207 Northeastern\n",
      "[2015, 1842, 1831] [1802, 1777, 1740] 1834.5\n",
      "55/207 Christopher Newport\n",
      "[1730, 1554, 1493] [1516, 1437, 1316] 1507.6666666666667\n",
      "56/207 Victoria\n",
      "[] [] 0.0\n",
      "57/207 Boston University\n",
      "[1986, 1830, 1823] [1840, 1746, 1709] 1822.3333333333333\n",
      "58/207 Miami University\n",
      "[] [] 0.0\n",
      "59/207 Hampton\n",
      "[1844, 1625] [] 578.1666666666666\n",
      "60/207 Virginia\n",
      "[1676, 1263] [1344] 713.8333333333334\n",
      "61/207 Stevens\n",
      "[] [] 0.0\n",
      "62/207 Columbia\n",
      "[1326] [1325] 441.8333333333333\n",
      "63/207 NY Maritime\n",
      "[1620, 1370, 1361] [1664, 1368, 1315] 1449.6666666666667\n",
      "64/207 Kings Point\n",
      "[1898, 1489, 1432] [1665, 1482, 1203] 1528.1666666666667\n",
      "65/207 St. Mary's\n",
      "[2395, 2181, 2036] [2286, 1980, 1817] 2115.8333333333335\n",
      "66/207 Maryland\n",
      "[] [] 0.0\n",
      "67/207 Virginia Tech\n",
      "[] [] 0.0\n",
      "68/207 Drexel\n",
      "[] [] 0.0\n",
      "69/207 Maryland/Baltimore\n",
      "[] [] 0.0\n",
      "70/207 Buffalo\n",
      "71/207 UC Santa Cruz\n",
      "[1662, 1608, 1499] [] 794.8333333333334\n",
      "72/207 Santa Clara\n",
      "[] [] 0.0\n",
      "73/207 Wisconsin\n",
      "[2017, 1861, 1712] [1722, 1645, 1519] 1746.0\n",
      "74/207 Michigan\n",
      "[2007, 1296, 1192] [1414, 1387, 1223] 1419.8333333333333\n",
      "75/207 Washington College\n",
      "[1499, 1000] [1108] 601.1666666666666\n",
      "76/207 Minnesota\n",
      "[] [] 0.0\n",
      "77/207 Yale\n",
      "[2454, 2425, 2418] [2322, 2293, 2195] 2351.1666666666665\n",
      "78/207 Hobart & William\n",
      "[2232, 2168, 1503] [2142, 2122, 1661] 1971.3333333333333\n",
      "79/207 Vermont\n",
      "[1888, 1727, 1662] [1659, 1632, 1562] 1688.3333333333333\n",
      "80/207 Connecticut College\n",
      "[2029, 1676, 1668] [1904, 1587, 1556] 1736.6666666666667\n",
      "81/207 Harvard\n",
      "[2536, 2403, 2216] [2426, 2303, 2056] 2323.3333333333335\n",
      "82/207 Roger Williams\n",
      "[2558, 2383, 2247] [2387, 2244, 2168] 2331.1666666666665\n",
      "83/207 Syracuse\n",
      "[] [] 0.0\n",
      "84/207 Tufts\n",
      "[2252, 1963, 1916] [2090, 2008, 1908] 2022.8333333333333\n",
      "85/207 Middlebury\n",
      "[] [] 0.0\n",
      "86/207 New College\n",
      "87/207 William and Mary\n",
      "[] [] 0.0\n",
      "88/207 Gannon\n",
      "89/207 Boston College\n",
      "[2326, 2261, 2173] [2489, 2074, 1980] 2217.1666666666665\n",
      "90/207 Stanford\n",
      "[2530, 2504, 2483] [2460, 2398, 2321] 2449.3333333333335\n",
      "91/207 Bowdoin\n",
      "[2361, 2172, 1934] [2180, 2083, 1980] 2118.3333333333335\n",
      "92/207 Lewis & Clark\n",
      "93/207 Monmouth\n",
      "[] [] 0.0\n",
      "94/207 American\n",
      "[] [] 0.0\n",
      "95/207 Michigan State\n",
      "[] [] 0.0\n",
      "96/207 Hope\n",
      "[] [] 0.0\n",
      "97/207 Western Michigan\n",
      "[] [] 0.0\n",
      "98/207 Toledo\n",
      "[] [] 0.0\n",
      "99/207 Ohio State\n",
      "[] [] 0.0\n",
      "100/207 Mass Maritime\n",
      "[1386, 1264, 844] [1305] 799.8333333333334\n",
      "101/207 Coast Guard\n",
      "[2432, 2399, 2005] [2197, 2152, 1794] 2163.1666666666665\n",
      "102/207 Bates\n",
      "[1156] [1409] 427.5\n",
      "103/207 Fairfield\n",
      "[] [1129] 188.16666666666666\n",
      "104/207 Sacred Heart\n",
      "[] [] 0.0\n",
      "105/207 Wentworth Institute\n",
      "[] [] 0.0\n",
      "106/207 Providence\n",
      "107/207 Iowa State\n",
      "108/207 Iowa\n",
      "109/207 Indiana\n",
      "[] [] 0.0\n",
      "110/207 Davidson\n",
      "[] [] 0.0\n",
      "111/207 Oregon State\n",
      "[] [] 0.0\n",
      "112/207 Western Washington\n",
      "[] [] 0.0\n",
      "113/207 U. Rochester\n",
      "[] [] 0.0\n",
      "114/207 Army\n",
      "[] [] 0.0\n",
      "115/207 New Hampshire\n",
      "[1495] [] 249.16666666666666\n",
      "116/207 U. Connecticut\n",
      "[] [] 0.0\n",
      "117/207 UMass Dartmouth\n",
      "[] [] 0.0\n",
      "118/207 Wesleyan\n",
      "[] [] 0.0\n",
      "119/207 U. Mass/ Amherst\n",
      "[] [] 0.0\n",
      "120/207 U New England\n",
      "121/207 Denison\n",
      "122/207 Northern Michigan\n",
      "[] [] 0.0\n",
      "123/207 Ohio\n",
      "124/207 Pennsylvania\n",
      "[2151, 2052, 2039] [1978, 1912, 1907] 2006.5\n",
      "125/207 Villanova\n",
      "[] [] 0.0\n",
      "126/207 Maine Maritime\n",
      "[1163, 1110, 1000] [1353, 1045, 1014] 1114.1666666666667\n",
      "127/207 Michigan Tech\n",
      "[] [] 0.0\n",
      "128/207 Illinois\n",
      "[] [] 0.0\n",
      "129/207 Chicago\n",
      "[] [] 0.0\n",
      "130/207 Northwestern\n",
      "[1897, 1745, 1353] [1703, 1179, 1155] 1505.3333333333333\n",
      "131/207 Grand Valley State\n",
      "[] [] 0.0\n",
      "132/207 Washington U\n",
      "[] [] 0.0\n",
      "133/207 Marquette\n",
      "[] [] 0.0\n",
      "134/207 Lake Forest\n",
      "[] [] 0.0\n",
      "135/207 Cornell\n",
      "[2332, 2101, 1718] [2088, 1917, 1884] 2006.6666666666667\n",
      "136/207 Oregon\n",
      "[1490] [1032] 420.3333333333333\n",
      "137/207 Portland State\n",
      "138/207 Princeton\n",
      "[1617, 1459, 1357] [1474, 1455, 1414] 1462.6666666666667\n",
      "139/207 Queen's\n",
      "[] [] 0.0\n",
      "140/207 Penn State\n",
      "[] [] 0.0\n",
      "141/207 Ocean County\n",
      "142/207 Delaware\n",
      "[] [] 0.0\n",
      "143/207 Rutgers\n",
      "[] [] 0.0\n",
      "144/207 Worcester Polytech\n",
      "[] [] 0.0\n",
      "145/207 Emmanuel College\n",
      "146/207 St. John's\n",
      "[] [] 0.0\n",
      "147/207 U Pittsburgh\n",
      "[] [] 0.0\n",
      "148/207 Webb Institute\n",
      "[2093, 2021, 1906] [1688, 1653, 1480] 1806.8333333333333\n",
      "149/207 McGill\n",
      "[] [] 0.0\n",
      "150/207 Citadel\n",
      "[1679, 1627, 1277] [1531, 1521, 1505] 1523.3333333333333\n",
      "151/207 Colgate\n",
      "[] [] 0.0\n",
      "152/207 Catholic U America\n",
      "[] [] 0.0\n",
      "153/207 Loyola College\n",
      "[] [] 0.0\n",
      "154/207 Ottawa\n",
      "155/207 Royal Military\n",
      "156/207 Dalhousie\n",
      "157/207 U Toronto\n",
      "[] [] 0.0\n",
      "158/207 New Orleans\n",
      "159/207 Kansas\n",
      "[] [1164] 194.0\n",
      "160/207 Bentley\n",
      "[] [] 0.0\n",
      "161/207 Brandeis\n",
      "[] [] 0.0\n",
      "162/207 Cal Maritime\n",
      "[2196, 2131, 1633] [2110, 1811] 1646.8333333333333\n",
      "163/207 San Diego State\n",
      "[1550] [] 258.3333333333333\n",
      "164/207 Loyola\n",
      "165/207 North Texas\n",
      "166/207 Vanderbilt\n",
      "[] [] 0.0\n",
      "167/207 Purdue\n",
      "[1493] [] 248.83333333333334\n",
      "168/207 North Carolina\n",
      "[] [] 0.0\n",
      "169/207 Hillsdale\n",
      "[] [] 0.0\n",
      "170/207 Amherst\n",
      "[] [] 0.0\n",
      "171/207 Williams\n",
      "[] [] 0.0\n",
      "172/207 Hamilton\n",
      "[] [] 0.0\n",
      "173/207 Rochester\n",
      "[] [] 0.0\n",
      "174/207 Wellesley\n",
      "175/207 Hosei Univerisity\n",
      "176/207 Colorado\n",
      "177/207 John Carroll\n",
      "178/207 U.  Mass/ Boston\n",
      "179/207 Mercyhurst\n",
      "180/207 Penn State Behrend\n",
      "[] [] 0.0\n",
      "181/207 Indiana U Pennsylvan\n",
      "[] [] 0.0\n",
      "182/207 U Nebraska\n",
      "183/207 U Maine\n",
      "184/207 Texas Christian\n",
      "185/207 Embry-Riddle\n",
      "[1175, 986] [1072] 538.8333333333334\n",
      "186/207 Palm Beach Atlantic\n",
      "[] [] 0.0\n",
      "187/207 U of Central Florida\n",
      "[] [] 0.0\n",
      "188/207 Baldwin-Wallace\n",
      "189/207 Saint Mary's College\n",
      "[] [] 0.0\n",
      "190/207 Olin\n",
      "[1477] [] 246.16666666666666\n",
      "191/207 Baylor\n",
      "[] [] 0.0\n",
      "192/207 Texas Tech\n",
      "193/207 Wake Forest\n",
      "[] [] 0.0\n",
      "194/207 Georgia Southern\n",
      "195/207 East Carolina\n",
      "196/207 Florida Tech\n",
      "[1739, 1228, 1011] [1242, 738] 993.0\n",
      "197/207 Saint Thomas\n",
      "[] [] 0.0\n",
      "198/207 Cincinnati\n",
      "199/207 Florida Gulf Coast\n",
      "200/207 Saginaw Valley\n",
      "[] [] 0.0\n",
      "201/207 Coastal Georgia\n",
      "[] [] 0.0\n",
      "202/207 Cleveland State\n",
      "203/207 Sewanee\n",
      "204/207 Case Western\n",
      "[] [] 0.0\n",
      "205/207 Oklahoma\n",
      "[] [] 0.0\n",
      "206/207 Gonzaga\n",
      "[] [] 0.0\n"
     ]
    }
   ],
   "source": [
    "# %%scalene\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "\n",
    "def getCounts(races):\n",
    "    # season_counts = defaultdict(int)\n",
    "    season_counts = {}\n",
    "    \n",
    "    for race in races:\n",
    "        season = race[\"raceID\"].split(\"/\")[0]\n",
    "        if season not in season_counts.keys():\n",
    "            season_counts[season] = {}\n",
    "        if race['pos'] not in season_counts[season].keys():\n",
    "            season_counts[season][race['pos']] = 0\n",
    "        season_counts[season][race['pos']] += 1\n",
    "\n",
    "    return dict(season_counts)\n",
    "\n",
    "# batch = db.batch()\n",
    "col = db.collection('eloTeams')\n",
    "teams = []\n",
    "scrape = False\n",
    "teamNames = teamRegions.keys()\n",
    "lenteams = len(teamNames)\n",
    "\n",
    "season_mask = df_sailors['Seasons'].apply(lambda x: targetSeason in x['skipper'] or targetSeason in x['crew'])\n",
    "\n",
    "# Explode the Teams column to enable grouping\n",
    "df_exploded = df_sailors.loc[season_mask].explode('Teams')\n",
    "\n",
    "# Group by team and compute necessary aggregates\n",
    "team_stats = df_exploded.groupby('Teams').agg(\n",
    "    numCurMembers=('Teams', 'count'),\n",
    "    avgSkipperOrdinal=('SkipperOrdinal', 'mean'),\n",
    "    avgCrewOrdinal=('CrewOrdinal', 'mean'),\n",
    "    avgSkipperRatio=('skipperAvgRatio', 'mean'),\n",
    "    avgCrewRatio=('crewAvgRatio', 'mean')\n",
    ")\n",
    "\n",
    "# Calculate the average values as in the original code\n",
    "team_stats['avg'] = (team_stats['avgSkipperOrdinal'] + team_stats['avgCrewOrdinal']) / 2\n",
    "team_stats['avgRatio'] = (team_stats['avgSkipperRatio'] + team_stats['avgCrewRatio']) / 2\n",
    "\n",
    "team_stats = team_stats.reindex(teamNames, fill_value=0)\n",
    "\n",
    "team_link_map = df_races.drop_duplicates('Team').set_index('Team')['Teamlink'].to_dict()\n",
    "\n",
    "# Optional: Loop for printing (if necessary)\n",
    "for i, (team, row) in enumerate(team_stats.iterrows()):\n",
    "    print(f\"{i}/{len(team_stats)} {team}\")\n",
    "    avg = row['avg']\n",
    "    avgRatio = row['avgRatio']\n",
    "    numCurMembers = row['numCurMembers']\n",
    "\n",
    "# for i,team in enumerate(teamNames):\n",
    "#     print(f\"{i}/{lenteams} {team}\")\n",
    "#     temp = df_sailors.loc[(df_sailors['Teams'].apply(lambda x: team in x)) & (df_sailors['Seasons'].apply(lambda x: 'f24' in x['skipper'] or 'f24' in x['crew']))]\n",
    "#     avg = (temp.loc[df_sailors['Seasons'].apply(lambda x: 'f24' in x['skipper']), 'SkipperOrdinal'].mean() + temp.loc[df_sailors['Seasons'].apply(lambda x: 'f24' in x['crew']), 'CrewOrdinal'].mean()) / 2\n",
    "#     avgRatio = (temp.loc[df_sailors['Seasons'].apply(lambda x: 'f24' in x['crew']),'skipperAvgRatio'].mean() + temp.loc[df_sailors['Seasons'].apply(lambda x: 'f24' in x['crew']),'crewAvgRatio'].mean()) / 2\n",
    "#     numCurMembers = len(temp)\n",
    "    \n",
    "    region = teamRegions[team]\n",
    "    # teamLink = df_races.loc[df_races['Team'] == team, 'Teamlink'].iloc[0]\n",
    "    teamLink = team_link_map.get(team, None)  # Default to None if team not found\n",
    "    url = f\"https://scores.collegesailing.org/schools/{teamLink.split(\"/\")[2]}\"\n",
    "    \n",
    "    if scrape:\n",
    "        page = requests.get(url)\n",
    "        teamPage = BeautifulSoup(page.content, 'html.parser')\n",
    "        \n",
    "        try:\n",
    "            region = teamPage.find('span', class_=\"page-info-value\").contents[0].contents[0]\n",
    "        except:\n",
    "            print(url)\n",
    "            continue\n",
    "        \n",
    "    filtered_people = [p for p in people.values() if team in p.teams]\n",
    "    \n",
    "    members = [{\"name\": p.name,\n",
    "                \"key\": p.key,\n",
    "                \"gender\": p.gender,\n",
    "                \"year\": str(p.year),\n",
    "                'teams': list(p.teams),\n",
    "                'skipperRating': int(p.sr.ordinal(target=targetElo, alpha=200 / model.sigma)),\n",
    "                'crewRating': int(p.cr.ordinal(target=targetElo, alpha=200 / model.sigma)),\n",
    "                'womenSkipperRating': int(p.wsr.ordinal(target=targetElo, alpha=200 / model.sigma)),\n",
    "                'womenCrewRating': int(p.wcr.ordinal(target=targetElo, alpha=200 / model.sigma)),\n",
    "                'avgSkipperRatio': float(p.avgSkipperRatio),\n",
    "                'avgCrewRatio': float(p.avgCrewRatio),\n",
    "                'raceCount': getCounts(p.races),\n",
    "                'seasons':{'skipper': list(p.seasons['skipper']), 'crew': list(p.seasons['crew'])},\n",
    "                'cross': sum([race['cross'] for race in p.races]),\n",
    "                'outLinks': sum([race['outLinks'] for race in p.races]),\n",
    "                'skipperRank': int(p.skipperRank),\n",
    "                'crewRank': int(p.crewRank),\n",
    "                'womenSkipperRank': int(p.womenSkipperRank),\n",
    "                'womenCrewRank': int(p.womenCrewRank)\n",
    "                } for p in filtered_people]\n",
    "    \n",
    "    teamRating = 0\n",
    "    if numCurMembers > 0:\n",
    "        teamRatingSkipper = sum([p['skipperRating'] * (p['raceCount'][targetSeason]['Skipper']/ 5) for p in members \n",
    "                          if targetSeason in p['raceCount'].keys()\n",
    "                          if 'Skipper' in p['raceCount'][targetSeason].keys()\n",
    "                          and p['raceCount'][targetSeason]['Skipper'] > 5])\n",
    "        teamRatingCrew = sum([p['crewRating'] * (p['raceCount'][targetSeason]['Crew']/ 5) for p in members \n",
    "                          if targetSeason in p['raceCount'].keys()\n",
    "                          if 'Crew' in p['raceCount'][targetSeason].keys()\n",
    "                          and p['raceCount'][targetSeason]['Crew'] > 5])\n",
    "        teamRating = (teamRatingSkipper + teamRatingCrew) / numCurMembers\n",
    "    \n",
    "    topRating = 0\n",
    "    topWomenRating = 0\n",
    "    \n",
    "    numTops = 3\n",
    "    if numCurMembers > 0:\n",
    "        topSkippers = sorted([p['skipperRating'] for p in members\n",
    "                                #   if p['skipperRank'] != 0 # eligible as in outLinks > 70 and f24 in seasons\n",
    "                                  if p['cross'] > 20\n",
    "                                  and p['outLinks'] > 70\n",
    "                                  and targetSeason in p['seasons']['skipper']\n",
    "                                #   and 'f24' in p['raceCount'].keys() \n",
    "                                #   and p['raceCount']['f24'] > 5\n",
    "                                  ], reverse=True)[:numTops]\n",
    "        topSkipperSum = sum(topSkippers)\n",
    "        \n",
    "        topCrews = sorted([p['crewRating'] for p in members\n",
    "                            #    if p['crewRank'] != 0\n",
    "                               if p['cross'] > 20\n",
    "                               and p['outLinks'] > 70\n",
    "                               and targetSeason in p['seasons']['crew']\n",
    "                            #    and 'f24' in p['raceCount'].keys()\n",
    "                            #    and p['raceCount']['f24'] > 5\n",
    "                               ], reverse=True)[:numTops]\n",
    "        topCrewsSum = sum(topCrews)\n",
    "        \n",
    "        topRating = (topSkipperSum + topCrewsSum) / (numTops * 2)\n",
    "        print(topSkippers, topCrews, topRating)\n",
    "\n",
    "        # Women's\n",
    "        numTops = 2\n",
    "        topWomenSkippers = sorted([p['womenSkipperRating'] for p in members\n",
    "                                #   if p['skipperRank'] != 0\n",
    "                                  if p['cross'] > 20\n",
    "                                  and p['gender'] == 'F'\n",
    "                                  and targetSeason in p['raceCount'].keys() \n",
    "                                  and 'Skipper' in p['raceCount'][targetSeason].keys() \n",
    "                                  and p['raceCount'][targetSeason]['Skipper'] > 5\n",
    "                                  ], reverse=True)[:numTops]\n",
    "        topWomenSkipperSum = sum(topWomenSkippers)\n",
    "        \n",
    "        topWomenCrews = sorted([p['womenCrewRating'] for p in members\n",
    "                            #    if p['crewRank'] != 0\n",
    "                               if p['cross'] > 20\n",
    "                               and p['gender'] == 'F'\n",
    "                               and targetSeason in p['raceCount'].keys()\n",
    "                               and 'Crew' in p['raceCount'][targetSeason].keys() \n",
    "                               and p['raceCount'][targetSeason]['Crew'] > 5\n",
    "                               ], reverse=True)[:numTops]\n",
    "        topWomenCrewsSum = sum(topWomenCrews)\n",
    "        \n",
    "        topWomenRating = (topWomenSkipperSum + topWomenCrewsSum) / (numTops * 2)\n",
    "    \n",
    "    #'#1': ,'#2': ,\n",
    "    teams.append({\"name\":team, \"avg\": avg, 'avgRatio': avgRatio, 'topRating': topRating, 'topWomenRating': topWomenRating, 'teamRating': teamRating, \"region\": region, \"link\": url, 'memberCount': numCurMembers})\n",
    "    col.document(team.replace(\" \", \"-\").replace(\"/\", \"-\").lower()).set({\"name\":team, \"avg\": avg, 'avgRatio': avgRatio, \"region\": region, \"link\": url, 'members': members})\n",
    "    # if i > 20:\n",
    "    #     break\n",
    "#     if i % 20 == 0: # commit every 20 documents\n",
    "#             batch.commit()\n",
    "# batch.commit()\n",
    "doc = db.collection('vars').document('eloTeams').set({\"teams\": teams})\n",
    "# teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "topSkippers = []\n",
    "for p in sorted([p for p in people.values() if p.skipperRank <= 100 and p.skipperRank != 0 and 'f24' in p.seasons['skipper']],key=lambda p: p.skipperRank):\n",
    "    topSkippers.append({'name': p.name,'key': p.key, 'year':p.year, 'rank': int(p.skipperRank), 'team': list(p.teams),'gender': p.gender, 'rating': p.sr.ordinal(target=targetElo, alpha=200 / model.sigma), 'seasons': list(p.seasons['skipper'])})\n",
    "doc = db.collection('vars').document('topSkippers').set({\"sailors\": topSkippers})\n",
    "\n",
    "topCrews = []\n",
    "for p in sorted([p for p in people.values() if p.crewRank <= 100 and p.crewRank != 0 and 'f24' in p.seasons['crew']],key=lambda p: p.crewRank):\n",
    "    topCrews.append({'name': p.name,'key': p.key, 'year':p.year, 'rank': int(p.crewRank), 'team': list(p.teams),'gender': p.gender, 'rating': p.cr.ordinal(target=targetElo, alpha=200 / model.sigma), 'seasons': list(p.seasons['crew'])})\n",
    "doc = db.collection('vars').document('topCrews').set({\"sailors\": topCrews})\n",
    "\n",
    "#Womens\n",
    "topSkippers = []\n",
    "for p in sorted([p for p in people.values() if p.womenSkipperRank <= 100 and p.womenSkipperRank != 0 and 'f24' in p.seasons['skipper']],key=lambda p: p.womenSkipperRank):\n",
    "    topSkippers.append({'name': p.name,'key': p.key, 'year':p.year, 'rank': int(p.womenSkipperRank), 'team': list(p.teams),'gender': p.gender, 'rating': p.wsr.ordinal(target=targetElo, alpha=200 / model.sigma), 'seasons': list(p.seasons['skipper'])})\n",
    "doc = db.collection('vars').document('topWomenSkippers').set({\"sailors\": topSkippers})\n",
    "topCrews = []\n",
    "for p in sorted([p for p in people.values() if p.womenCrewRank <= 100 and p.womenCrewRank != 0 and 'f24' in p.seasons['crew']],key=lambda p: p.womenCrewRank):\n",
    "    topCrews.append({'name': p.name,'key': p.key, 'year':p.year, 'rank': int(p.womenCrewRank), 'team': list(p.teams),'gender': p.gender, 'rating': p.wcr.ordinal(target=targetElo, alpha=200 / model.sigma), 'seasons': list(p.seasons['crew'])})\n",
    "doc = db.collection('vars').document('topWomenCrews').set({\"sailors\": topCrews})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "flattened_dict = {p.key: {'team': p.teams[-1], 'year': p.year, 'name': p.name} for p in people.values() if 'f24' in p.seasons['skipper'] or 'f24' in p.seasons['crew']}\n",
    "# print(flattened_dict)\n",
    "doc = db.collection('vars').document('allSailors').set({'allSailors': json.dumps(flattened_dict, separators=(',', ':'))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1724"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_races_full['Regatta'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s16/peter-wenner-rainbow-invite 2016-01-16 00:00:00\n",
      "s16/jeff-simon 2016-01-23 00:00:00\n",
      "s16/seisa-qualifier 2016-01-30 00:00:00\n",
      "s16/harris-kempner 2016-02-06 00:00:00\n",
      "s16/old-south 2016-02-13 00:00:00\n",
      "s16/usf-women 2016-02-20 00:00:00\n",
      "s16/nelson-roltsch 2016-02-20 00:00:00\n",
      "s16/saisa-open 2016-02-20 00:00:00\n",
      "s16/anteater-open 2016-02-20 00:00:00\n",
      "s16/charleston-women 2016-02-27 00:00:00\n",
      "s16/barnyard-bazaar 2016-02-27 00:00:00\n",
      "s16/sea-to-sky 2016-02-27 00:00:00\n",
      "s16/eckerd-interconference 2016-03-05 00:00:00\n",
      "s16/odu-open 2016-03-05 00:00:00\n",
      "s16/mustang-open 2016-03-05 00:00:00\n",
      "s16/saisa-north-points 2016-03-05 00:00:00\n",
      "s16/charleston-spring-coed 2016-03-12 00:00:00\n",
      "s16/navy-spring-women 2016-03-12 00:00:00\n",
      "s16/2016-sailpack-invitational 2016-03-12 00:00:00\n",
      "s16/ice-breaker 2016-03-12 00:00:00\n",
      "s16/south-points-ncf 2016-03-12 00:00:00\n",
      "s16/saisa-sp 2016-03-12 00:00:00\n",
      "s16/woollum 2016-03-12 00:00:00\n",
      "s16/st-mary-women-interconference 2016-03-19 00:00:00\n",
      "s16/west-canada-cup 2016-03-19 00:00:00\n",
      "s16/saisa-south-pts 2016-03-19 00:00:00\n",
      "s16/william-mary-spring-open 2016-03-19 00:00:00\n",
      "s16/north-points 2016-03-19 00:00:00\n",
      "s16/freshman-icebreaker 2016-03-19 00:00:00\n",
      "s16/vietor 2016-03-19 00:00:00\n",
      "s16/neisa-central 2016-03-20 00:00:00\n",
      "s16/hanbury 2016-03-26 00:00:00\n",
      "s16/hawkeye-invitational 2016-03-26 00:00:00\n",
      "s16/north-points-tennessee 2016-03-26 00:00:00\n",
      "s16/saisa-south-points 2016-03-26 00:00:00\n",
      "s16/central-series 2016-03-26 00:00:00\n",
      "s16/seisa-women 2016-04-02 00:00:00\n",
      "s16/dellenbaugh-women 2016-04-02 00:00:00\n",
      "s16/st-francis-interconference 2016-04-02 00:00:00\n",
      "s16/gamecock-sailing-invitational 2016-04-02 00:00:00\n",
      "s16/stony-brook-cup 2016-04-02 00:00:00\n",
      "s16/webb 2016-04-02 00:00:00\n",
      "s16/bu-trophy 2016-04-02 00:00:00\n",
      "s16/central-series-spring-2016 2016-04-02 00:00:00\n",
      "s16/saisa-coed-champs 2016-04-09 00:00:00\n",
      "s16/buckeye 2016-04-09 00:00:00\n",
      "s16/emily-wick 2016-04-09 00:00:00\n",
      "s16/villanova-spring-open 2016-04-09 00:00:00\n",
      "s16/ne-dinghy-tournament 2016-04-09 00:00:00\n",
      "s16/admiral-alymers 2016-04-09 00:00:00\n",
      "s16/pccscsouth-designate 2016-04-09 00:00:00\n",
      "s16/lake-macatawa-invitational 2016-04-09 00:00:00\n",
      "s16/tyrell 2016-04-10 00:00:00\n",
      "s16/mcsa-fleet-race-championships 2016-04-15 00:00:00\n",
      "s16/2016-seisa-coed-dinghy 2016-04-16 00:00:00\n",
      "s16/pccsc-women 2016-04-16 00:00:00\n",
      "s16/navy-spring 2016-04-16 00:00:00\n",
      "s16/rainier-cup 2016-04-16 00:00:00\n",
      "s16/president 2016-04-16 00:00:00\n",
      "s16/thompson 2016-04-16 00:00:00\n",
      "s16/mosbacher-owen-knapp-trophies 2016-04-16 00:00:00\n",
      "s16/leroy-grant 2016-04-16 00:00:00\n",
      "s16/bc-central-series 2016-04-16 00:00:00\n",
      "s16/oberg 2016-04-16 00:00:00\n",
      "s16/south-seres 2016-04-16 00:00:00\n",
      "s16/pccsc-coed 2016-04-22 00:00:00\n",
      "s16/reed 2016-04-23 00:00:00\n",
      "s16/mcsa-women 2016-04-23 00:00:00\n",
      "s16/saisa-women-champs 2016-04-23 00:00:00\n",
      "s16/maisa-womens 2016-04-23 00:00:00\n",
      "s16/nwicsa-women 2016-04-23 00:00:00\n",
      "s16/admiral-cup 2016-04-23 00:00:00\n",
      "s16/george-morris 2016-04-23 00:00:00\n",
      "s16/81st-boston-dinghy-challenge-cup 2016-04-23 00:00:00\n",
      "s16/delaware-spring-open 2016-04-23 00:00:00\n",
      "s16/greater-new-york-dinghy 2016-04-23 00:00:00\n",
      "s16/wisco-division 2016-04-23 00:00:00\n",
      "s16/robert-arrigan 2016-04-23 00:00:00\n",
      "s16/otoole 2016-04-24 00:00:00\n",
      "s16/america-maisa-dinghy-champs 2016-04-30 00:00:00\n",
      "s16/coast-guard-alumni-bowl 2016-04-30 00:00:00\n",
      "s16/nwicsa-co-ed-fleet-race 2016-04-30 00:00:00\n",
      "s16/army-spring-open 2016-04-30 00:00:00\n",
      "s16/wesleyan-invite 2016-04-30 00:00:00\n",
      "s16/south-series 2016-04-30 00:00:00\n",
      "s16/gull-gust-2016 2016-04-30 00:00:00\n",
      "s16/mendums-pond-invite 2016-04-30 00:00:00\n",
      "s16/drexel-open 2016-05-07 00:00:00\n",
      "s16/gopher-invite 2016-05-07 00:00:00\n",
      "s16/jeremy-pinkerton 2016-05-07 00:00:00\n",
      "s16/engineer-cup 2016-05-14 00:00:00\n",
      "s16/sperry-women-east-semis 2016-05-24 00:00:00\n",
      "s16/sperry-women-west-semis 2016-05-24 00:00:00\n",
      "s16/sperry-sailing-women-nationals 2016-05-26 00:00:00\n",
      "s16/tufts-alumni 2016-05-28 00:00:00\n",
      "s16/gill-coed-west-semis 2016-05-31 00:00:00\n",
      "s16/gill-coed-east-semis 2016-05-31 00:00:00\n",
      "s16/gill-coed-national 2016-06-02 00:00:00\n",
      "f16/fall-fury 2016-09-10 00:00:00\n",
      "f16/harry-anderson-jr 2016-09-10 00:00:00\n",
      "f16/lark-invitational 2016-09-10 00:00:00\n",
      "f16/penobscot-bay-open 2016-09-10 00:00:00\n",
      "f16/riley-cup 2016-09-10 00:00:00\n",
      "f16/troy-swetnam 2016-09-10 00:00:00\n",
      "f16/mt-hope-bay-invite 2016-09-10 00:00:00\n",
      "f16/saisa-open 2016-09-10 00:00:00\n",
      "f16/jack-boehringer-52 2016-09-10 00:00:00\n",
      "f16/toni-deutsch 2016-09-10 00:00:00\n",
      "f16/fj-invitational 2016-09-11 00:00:00\n",
      "f16/nevins 2016-09-17 00:00:00\n",
      "f16/hatch-brown 2016-09-17 00:00:00\n",
      "f16/stu-nelson 2016-09-17 00:00:00\n",
      "f16/sacred-heart 2016-09-17 00:00:00\n",
      "f16/baldwin-wood 2016-09-17 00:00:00\n",
      "f16/saisa-sailpack-women 2016-09-17 00:00:00\n",
      "f16/stuart-walker-open 2016-09-17 00:00:00\n",
      "f16/colony-cup 2016-09-17 00:00:00\n",
      "f16/saisa-south-points 2016-09-17 00:00:00\n",
      "f16/north-points-tennessee 2016-09-17 00:00:00\n",
      "f16/buckeye-invite 2016-09-17 00:00:00\n",
      "f16/ny-maritime-fall-open 2016-09-17 00:00:00\n",
      "f16/central-series 2016-09-17 00:00:00\n",
      "f16/callagy-ross 2016-09-17 00:00:00\n",
      "f16/donaghy-bowl 2016-09-18 00:00:00\n",
      "f16/34th-stedman-hood 2016-09-24 00:00:00\n",
      "f16/timme-angsten 2016-09-24 00:00:00\n",
      "f16/st-mary-fall-interconference 2016-09-24 00:00:00\n",
      "f16/central-fall-qualifier 2016-09-24 00:00:00\n",
      "f16/south-tom-curtis 2016-09-24 00:00:00\n",
      "f16/north-fall 2016-09-24 00:00:00\n",
      "f16/dave-fallon 2016-09-24 00:00:00\n",
      "f16/amanda 2016-09-24 00:00:00\n",
      "f16/aggie-fall 2016-09-24 00:00:00\n",
      "f16/salt-pond-invite 2016-09-24 00:00:00\n",
      "f16/chris-loder 2016-09-24 00:00:00\n",
      "f16/saisa-sp 2016-09-24 00:00:00\n",
      "f16/saisa-women-fall-dinghy-champs 2016-10-01 00:00:00\n",
      "f16/susan-rogers-75 2016-10-01 00:00:00\n",
      "f16/jesuit-interconference 2016-10-01 00:00:00\n",
      "f16/danmark 2016-10-01 00:00:00\n",
      "f16/cazenovia-fall-open 2016-10-01 00:00:00\n",
      "f16/south 2016-10-01 00:00:00\n",
      "f16/canadian-american-cup 2016-10-01 00:00:00\n",
      "f16/kings-point-dinghy-open 2016-10-01 00:00:00\n",
      "f16/regis-bowl 2016-10-01 00:00:00\n",
      "f16/emma-biagioni 2016-10-01 00:00:00\n",
      "f16/philly-fleet-race 2016-10-01 00:00:00\n",
      "f16/pere-marquette 2016-10-01 00:00:00\n",
      "f16/owlapalooza 2016-10-01 00:00:00\n",
      "f16/hewitt 2016-10-01 00:00:00\n",
      "f16/george-warren-smith 2016-10-01 00:00:00\n",
      "f16/harvard-invitational 2016-10-01 00:00:00\n",
      "f16/saisa-sp4 2016-10-01 00:00:00\n",
      "f16/mystic-lake-invite 2016-10-02 00:00:00\n",
      "f16/women-weekday-invite 2016-10-05 00:00:00\n",
      "f16/david-lee-arnoff 2016-10-08 00:00:00\n",
      "f16/navy-fall-women 2016-10-08 00:00:00\n",
      "f16/moody 2016-10-08 00:00:00\n",
      "f16/mccurdy 2016-10-08 00:00:00\n",
      "f16/cascadia-cup 2016-10-08 00:00:00\n",
      "f16/south-series 2016-10-08 00:00:00\n",
      "f16/nicholas-barnett 2016-10-08 00:00:00\n",
      "f16/ucsd-open 2016-10-08 00:00:00\n",
      "f16/frosh-soph 2016-10-08 00:00:00\n",
      "f16/tufts-women 2016-10-08 00:00:00\n",
      "f16/protest 2016-10-09 00:00:00\n",
      "f16/yale-women-backup 2016-10-15 00:00:00\n",
      "f16/captain-hurst-bowl 2016-10-15 00:00:00\n",
      "f16/kathryn-hammond-backup 2016-10-22 00:00:00\n",
      "f16/sherman-hoyt 2016-10-22 00:00:00\n",
      "f16/mrs-hurst-bowl-backup 2016-10-22 00:00:00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m regatta \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(df_races_full[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegatta\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()):\n\u001b[0;32m----> 2\u001b[0m     races \u001b[38;5;241m=\u001b[39m df_races_full[\u001b[43mdf_races_full\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRegatta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mregatta\u001b[49m]\n\u001b[1;32m      3\u001b[0m     raceIDs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(races[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraceID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m      4\u001b[0m     links \u001b[38;5;241m=\u001b[39m races[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSailor\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.13.1/lib/python3.13/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.13.1/lib/python3.13/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.13.1/lib/python3.13/site-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.13.1/lib/python3.13/site-packages/pandas/core/ops/array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.13.1/lib/python3.13/site-packages/pandas/core/ops/array_ops.py:129\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    127\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# 'score': int(score), # Need to rewrite to include DNF and such (correctly evaluating score but its hard to tell )\n",
    "#                 'pos': type,\n",
    "#                 'predicted': pred[0],\n",
    "#                 'ratio': 1 - ((int(score) - 1) / (len(racers) - 1)), # Calculate ratio here\n",
    "#                 'change': change,\n",
    "#                 'regAvg': regattaAvg,\n",
    "#                 'cross': isCross,\n",
    "#                 'outLinks': outLinks,\n",
    "#                 'skipperRating': sailor.sr.ordinal(target=targetElo, alpha=200 / model.sigma), # add offset to prevent negative ratings\n",
    "#                 'crewRating': sailor.cr.ordinal(target=targetElo, alpha=200 / model.sigma), # add offset to prevent negative ratings\n",
    "#                 'womenSkipperRating': sailor.wsr.ordinal(target=targetElo, alpha=200 / model.sigma), # add offset to prevent negative ratings\n",
    "#                 'womenCrewRating': sailor.wcr.ordinal(target=targetElo, alpha=200 / model.sigma), # add offset to prevent negative ratings\n",
    "#                 'womens': womens,\n",
    "#                 'date' :date,\n",
    "#                 'partner': {'name': partner, 'link': partnerLink},\n",
    "#                 'venue': venue,\n",
    "#                 'raceID': actualID,\n",
    "#                 'scoring': scoring\n",
    "                \n",
    "for regatta in list(df_races_full['Regatta'].unique()):\n",
    "    races = df_races_full[df_races_full['Regatta'] == regatta]\n",
    "    raceIDs = list(races['raceID'].unique())\n",
    "    links = races['Sailor'].unique()\n",
    "    date = races['Date'].unique()[0]\n",
    "    venue = races['Venue'].unique()[0]\n",
    "    scoring = races['scoring'].unique()[0]\n",
    "    \n",
    "    racePpl = [{\n",
    "        \"key\":p.key, \n",
    "        \"Name\":p.name, \n",
    "        'Year': p.year,\n",
    "        \"Teams\": list(p.teams),\n",
    "        \"Rating\": int(p.r.mu),\n",
    "        \"GlobalRank\": int(p.rank),\n",
    "        \"races\": [{\n",
    "                'sailor': p.name,\n",
    "                'key': p.key,\n",
    "                'pos': race['pos'],\n",
    "                \"raceID\": race['raceID'],\n",
    "                \"score\": float(race['score']),\n",
    "                \"predicted\": int(race['predicted']), \n",
    "                \"change\": float(race['change']), \n",
    "                'newRating': float(race['newRating']),\n",
    "                'partner':race['partner'],\n",
    "                'ratio': float(race['ratio']),\n",
    "                } for race in p.races if race['raceID'].split(\"/\")[0] + \"/\" + race['raceID'].split(\"/\")[1] == regatta]\n",
    "        } for p in people.values() if p.name in links]\n",
    "    \n",
    "    # race = {'raceID':'', 'raceNum':0, 'div': '', 'sailors':[]}\n",
    "    # person = {'name':'', 'rating':0, 'change':0, 'team': '', 'pos': '', 'div':'', 'partner': ''}\n",
    "    doc = {'regattaName': regatta,'raceIDs':raceIDs,  'sailors': racePpl}\n",
    "    \n",
    "    # for race in races['raceID'].unique():\n",
    "    #     sailors = races[races['raceID'] == race, 'Sailor'].unique()\n",
    "    # for p in [p for p in people.values() if p.name in sailors]:\n",
    "        # racePpl.append({'name':p.name, 'rating':p.rating, 'changes':p.changes, 'team': p.team, 'pos': '', 'div':'', 'partner': ''})\n",
    "    # print(regatta)\n",
    "    # db.collection('eloRegattas').document().set({'regattaName': regatta,'raceIDs':raceIDs, 'sailors': racePpl}, timeout=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_collection(coll_ref, batch_size):\n",
    "    if batch_size == 0:\n",
    "        return\n",
    "\n",
    "    docs = coll_ref.list_documents(page_size=batch_size)\n",
    "    deleted = 0\n",
    "\n",
    "    for doc in docs:\n",
    "        if deleted % 50 == 0:\n",
    "            print(f\"{deleted} Deleting doc {doc.id} => {doc.get().to_dict()}\")\n",
    "        doc.delete()\n",
    "        deleted = deleted + 1\n",
    "\n",
    "    if deleted >= batch_size:\n",
    "        return delete_collection(coll_ref, batch_size)\n",
    "col = db.collection('eloRegattas')\n",
    "delete_collection(col, 400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
